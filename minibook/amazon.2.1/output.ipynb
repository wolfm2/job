{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.002409,
     "end_time": "2018-04-12T23:02:06.796356",
     "exception": false,
     "start_time": "2018-04-12T23:02:06.793947",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.282795,
     "end_time": "2018-04-12T23:02:07.093281",
     "exception": false,
     "start_time": "2018-04-12T23:02:06.810486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.013688,
     "end_time": "2018-04-12T23:02:07.107059",
     "exception": false,
     "start_time": "2018-04-12T23:02:07.093371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.system('ps aux | grep wolfm2')\n",
    "#os.system('killall -s SIGKILL -u wolfm2')\n",
    "#os.system('cp /home/wolfm2/job.sh .; echo test 1>&2') #; cp ../job.log ../jerbb.txt')\n",
    "\n",
    "isTraining = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-12T23:02:07.107104",
     "exception": false,
     "start_time": "2018-04-12T23:02:07.107098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 1.373422,
     "end_time": "2018-04-12T23:02:08.489140",
     "exception": false,
     "start_time": "2018-04-12T23:02:07.115718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318500, 14)\n"
     ]
    }
   ],
   "source": [
    "if isTraining:\n",
    "    amazon = pd.read_csv('/home/wolfm2/amazon_data.0/raw_data_train.csv')\n",
    "    #amazon = pd.read_csv('/home/eydu/amazon_data/raw_data_train.csv')\n",
    "    #amazon = pd.read_csv('/home/ich/amazon_data/raw_data_train.csv')\n",
    "else:\n",
    "    amazon = pd.read_csv('/home/wolfm2/amazon_data.0/raw_data_test.csv')\n",
    "\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.012266,
     "end_time": "2018-04-12T23:02:08.501497",
     "exception": false,
     "start_time": "2018-04-12T23:02:08.489231",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0       39590        218604  218605  B003TWBUWI  A3W25DGQAN3BCA   \n",
      "1      366204        203525  203526  B000CQC04Q  A3QLP6M4RIT77H   \n",
      "2      292985        358338  358339  B001EO5Y7K  A1Q7A78VSQ5GQ4   \n",
      "3      425853        203051  203052  B000KEVF1O   A6NAF9GQHKOVO   \n",
      "4      205723        483843  483844  B003XDH6M6  A1X8BQQGCEHQ1V   \n",
      "\n",
      "                       ProfileName  HelpfulnessNumerator  \\\n",
      "0                          glouise                     1   \n",
      "1                       Snow Bound                     1   \n",
      "2  Nice Lady \"a reasonable person\"                     0   \n",
      "3                   KlutinaQuilter                     0   \n",
      "4   Kim Cantrell \"Soap Box Bandit\"                     1   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time  \\\n",
      "0                       1      4  1341705600   \n",
      "1                       1      5  1267228800   \n",
      "2                       0      5  1325980800   \n",
      "3                       0      5  1310342400   \n",
      "4                       2      2  1318291200   \n",
      "\n",
      "                                             Summary  \\\n",
      "0                            4 with reservations....   \n",
      "1                         I'm in LOVE with this tea!   \n",
      "2  Have tried many varieties of Turkish delight. ...   \n",
      "3                      Greenies, how can you say no?   \n",
      "4                   Stays With You Long After Eating   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  Okay, these were very moist and they did have ...        1.0    False  \n",
      "1  It is sinfully delicious and a nice way to end...        1.0    False  \n",
      "2  This Turkish Delight is soft and delectable. A...        NaN    False  \n",
      "3  Of course dogs love Greenies!  I was happy to ...        NaN    False  \n",
      "4  I love Pomegranate.  I love licorice.  I love ...        0.5    False  \n",
      "0.0732025117739\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-12T23:02:08.501676",
     "exception": false,
     "start_time": "2018-04-12T23:02:08.501670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.010761,
     "end_time": "2018-04-12T23:02:08.522117",
     "exception": false,
     "start_time": "2018-04-12T23:02:08.511356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.197987,
     "end_time": "2018-04-12T23:02:08.720190",
     "exception": false,
     "start_time": "2018-04-12T23:02:08.522203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 238.103266,
     "end_time": "2018-04-12T23:06:06.823545",
     "exception": false,
     "start_time": "2018-04-12T23:02:08.720279",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318500, 524288)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# amazon['reviewLen'] = amazon['Text'].str.len() # Use this later /X as gross dummy\n",
    "\n",
    "amazon['textLower'] = amazon['Text'].str.lower()\n",
    "# look at the text  token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b',\n",
    "if isTraining:\n",
    "    hv0 = HashingVectorizer(n_features=2 ** 19, non_negative=True, tokenizer=LemmaTokenizer(), strip_accents=ascii,  stop_words={'english'}, token_pattern = r'\\b[a-zA-Z]{3,}\\b', ngram_range=(1,3))\n",
    "    X_hv0 = hv0.fit_transform(amazon.textLower)\n",
    "    joblib.dump(hv0, 'hv0.pkl') # pickle\n",
    "else:\n",
    "    hv0 = joblib.load('hv0.pkl') # pickle\n",
    "    X_hv0 = hv0.transform(amazon.textLower)\n",
    "\n",
    "\n",
    "# amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "# amazon['sfLower'] = amazon['summaryFilter'].str.lower()\n",
    "# # and a second domain where we look at the summary\n",
    "# if isTraining:\n",
    "#     hv1 = HashingVectorizer(n_features=2 ** 19, non_negative=True, tokenizer=LemmaTokenizer(), ngram_range=(1,3))\n",
    "#     X_hv1 = hv1.fit_transform(amazon.sfLower) \n",
    "#     joblib.dump(hv1, 'hv1.pkl') # pickle\n",
    "# else:\n",
    "#     hv1 = joblib.load('hv1.pkl') # pickle\n",
    "#     X_hv1 = hv1.transform(amazon.sfLower) \n",
    "\n",
    "# Another hash domain we want to count but not tfidf\n",
    "# amazon['timeFilter'] = amazon['Time'].apply(lambda x: str(int(x)%(86400 * 7))) # converts to day of week\n",
    "# hv2 = HashingVectorizer(n_features=2 ** 17, non_negative=True, strip_accents=ascii, \n",
    "#                            ngram_range=(1,1)) \n",
    "# X_hv2 = hv2.fit_transform(amazon.timeFilter + \" \" + amazon.ProductId + \" \" + amazon.UserId) # mw adds uid as token\n",
    "\n",
    "# amazon['logReviewLen'] = np.round(np.log(amazon['Text'].str.len()),decimals=1) + 10\n",
    "# amazon.hist(column=\"logReviewLen\")\n",
    "\n",
    "amazon['ScoreX'] = amazon['Score'].apply(lambda x: str(x)) # make score acceptable\n",
    "# amazon['sLogReviewLen'] = amazon['logReviewLen'].apply(lambda x: str(x)) # make score acceptable\n",
    "if isTraining:\n",
    "    hv2 = HashingVectorizer(n_features=2 ** 17, non_negative=True, ngram_range=(1,1)) \n",
    "    X_hv2 = hv2.fit_transform(amazon.ScoreX) # mw adds uid as token\n",
    "    joblib.dump(hv2, 'hv2.pkl') # pickle\n",
    "else:\n",
    "    hv2 = joblib.load('hv2.pkl') # pickle\n",
    "    X_hv2 = hv2.transform(amazon.ScoreX) # mw adds uid as token\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hv = sp.hstack([X_hv0], format='csr')\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.009241,
     "end_time": "2018-04-12T23:06:06.832876",
     "exception": false,
     "start_time": "2018-04-12T23:06:06.823635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = amazon.UserId + \" \" +  amazon.Text\n",
    "# x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.011091,
     "end_time": "2018-04-12T23:06:06.846570",
     "exception": false,
     "start_time": "2018-04-12T23:06:06.835479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "# if isTraining:\n",
    "#     joblib.dump(hv0, 'hv0.pkl') # pickle\n",
    "#     joblib.dump(hv1, 'hv1.pkl') # pickle\n",
    "#     joblib.dump(hv2, 'hv2.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 8.412126,
     "end_time": "2018-04-12T23:06:15.258834",
     "exception": false,
     "start_time": "2018-04-12T23:06:06.846708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "if isTraining:\n",
    "    transformer = TfidfTransformer()\n",
    "    X_tfidf = transformer.fit_transform(X_hv)\n",
    "    joblib.dump(transformer, 'transformer.pkl') # pickle\n",
    "else:\n",
    "    transformer = joblib.load('transformer.pkl') # pickle\n",
    "    X_tfidf = transformer.transform(X_hv)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.009881,
     "end_time": "2018-04-12T23:06:15.268802",
     "exception": false,
     "start_time": "2018-04-12T23:06:15.258921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-04-12T23:06:15.271237",
     "exception": false,
     "start_time": "2018-04-12T23:06:15.271230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 11.543337,
     "end_time": "2018-04-12T23:06:26.824261",
     "exception": false,
     "start_time": "2018-04-12T23:06:15.280924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "import re\n",
    "\n",
    "#amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "#amazon['summaryLen'] = amazon['summaryFilter'].str.len()\n",
    "\n",
    "#amazon['rlMeanDist'] = amazon['reviewLen'].apply(lambda x: abs(x-80)) # 80 is avg summary len. Thx George!\n",
    "#amazon['slMeanDist'] = amazon['summaryLen'].apply(lambda x: abs(x-8)) # 8. just guessing here.\n",
    "\n",
    "#import zlib\n",
    "#amazon['nameHash'] = zlib.crc32(str(amazon['UserId']).encode('utf8'))\n",
    "#amazon['nameHash'] = amazon['UserId'].apply(lambda x: zlib.crc32(str(x).encode('utf8'))) # bad. don't do it this way\n",
    "\n",
    "# stackoverflow.com/questions/15772371/finding-average-length-of-items-in-a-list-python\n",
    "# averages array element lengths\n",
    "def avgLen(text, regex):\n",
    "    lst = re.findall(regex, text)\n",
    "    lengths = [len(i) for i in lst]\n",
    "    return 0 if len(lengths) == 0 else (float(sum(lengths)) / len(lengths)) \n",
    "\n",
    "# ratio of regex to whole\n",
    "def cRatio(text, regex):\n",
    "    num = len(re.findall(regex, text))\n",
    "    text = \"\" if text is np.nan else text\n",
    "    den = len(text)\n",
    "    return 0 if den == 0 else num / den\n",
    "\n",
    "# Review Len\n",
    "amazon['summaryLen'] = amazon['Text'].str.len()\n",
    "\n",
    "# Num Words\n",
    "amazon['numWords'] = amazon['Text'].apply(lambda x: len(re.findall(\"[a-zA-Z']+\", x)))\n",
    "\n",
    "# Num Cap Words\n",
    "amazon['numCapWords'] = amazon['Text'].apply(lambda x: len(re.findall(\"[A-Z']+\", x)))\n",
    "\n",
    "# Avg Sentence Len\n",
    "amazon['avgSenLen'] = amazon['Text'].apply(lambda x: avgLen(x, \"[a-zA-Z' ]+\"))\n",
    "\n",
    "# Avg Word Len\n",
    "amazon['avgWrdLen'] = amazon['Text'].apply(lambda x: avgLen(x, \"[a-zA-Z']+\"))\n",
    "\n",
    "# ! Ratio\n",
    "# amazon['ratioBang'] = amazon['Text'].apply(lambda x: cRatio(x, \"\\!\"))\n",
    "\n",
    "# ? Ratio                             \n",
    "# amazon['ratioQmark'] = amazon['Text'].apply(lambda x: cRatio(x, \"\\?\"))\n",
    "\n",
    "# X_quant_features = amazon[[\"Score\", \"reviewLen\", \"summaryLen\", \"rlMeanDist\", \"slMeanDist\"]]\n",
    "# print(X_quant_features.head(10))\n",
    "# print(type(X_quant_features))\n",
    "X_quant_features = amazon[['summaryLen', 'numWords', 'numCapWords', 'avgSenLen', 'avgWrdLen']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-12T23:06:26.824373",
     "exception": false,
     "start_time": "2018-04-12T23:06:26.824367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 16.44705,
     "end_time": "2018-04-12T23:06:43.281050",
     "exception": false,
     "start_time": "2018-04-12T23:06:26.834000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318500, 524293)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])  # we dont want to penalize hv2 w tfidf MW\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-12T23:06:43.281149",
     "exception": false,
     "start_time": "2018-04-12T23:06:43.281143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.119572,
     "end_time": "2018-04-12T23:06:45.410590",
     "exception": false,
     "start_time": "2018-04-12T23:06:43.291018",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(318500, 524293)\n"
     ]
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "if isTraining:\n",
    "    sc = StandardScaler(with_mean=False)\n",
    "    X = sc.fit_transform(X_matrix)\n",
    "    joblib.dump(sc, 'sc.pkl') # pickle\n",
    "else:\n",
    "    sc = joblib.load('sc.pkl')\n",
    "    X = sc.transform(X_matrix)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-12T23:06:45.410684",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.410678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.010032,
     "end_time": "2018-04-12T23:06:45.430635",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.420603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 8e-06,
     "end_time": "2018-04-12T23:06:45.432964",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.432956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.011992,
     "end_time": "2018-04-12T23:06:45.455232",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.443240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 0.010416,
     "end_time": "2018-04-12T23:06:45.465679",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.455263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: SVM, linear\n",
    "# from sklearn import linear_model\n",
    "# svm = linear_model.SGDClassifier()\n",
    "# svm.fit(X, y)\n",
    "\n",
    "# joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "if not isTraining:\n",
    "    svm = joblib.load('best.svm.pkl')\n",
    "    svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "    svm_performance.compute_measures()\n",
    "    print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.011928,
     "end_time": "2018-04-12T23:06:45.479181",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.467253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: logistic regression\n",
    "# from sklearn import linear_model\n",
    "# #lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "# lgs = linear_model.SGDClassifier(loss='log', n_iter=1000, alpha=0.1)\n",
    "\n",
    "# lgs.fit(X, y)\n",
    "# joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "if not isTraining:\n",
    "    lgs = joblib.load('best.lgs.pkl')\n",
    "    lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "    lgs_performance.compute_measures()\n",
    "    print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.011906,
     "end_time": "2018-04-12T23:06:45.491202",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.479296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# nbs = MultinomialNB()\n",
    "# nbs.fit(X, y)\n",
    "# joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "if not isTraining:\n",
    "    nbs = joblib.load('best.nbs.pkl')\n",
    "    nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "    nbs_performance.compute_measures()\n",
    "    print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.012074,
     "end_time": "2018-04-12T23:06:45.503307",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.491233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Ridge Regression Classifier\n",
    "# from sklearn import linear_model\n",
    "# rdg = linear_model.RidgeClassifier()\n",
    "# rdg.fit(X, y)\n",
    "# joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "if not isTraining:\n",
    "    rdg = joblib.load('best.rdg.pkl')\n",
    "    rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "    rdg_performance.compute_measures()\n",
    "    print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.015626,
     "end_time": "2018-04-12T23:06:45.518966",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.503340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "if not isTraining:\n",
    "    prc = joblib.load('best.prc.pkl')\n",
    "    prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "    prc_performance.compute_measures()\n",
    "    print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 12487.407233,
     "end_time": "2018-04-13T02:34:52.926261",
     "exception": false,
     "start_time": "2018-04-12T23:06:45.519028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=500,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 95.00139197,  91.31012956,  91.7343847 ,  90.70429913,\n",
      "        90.36137549,  90.21028821]), 'std_fit_time': array([ 0.66690345,  0.85694826,  0.66542218,  0.46818208,  0.31188319,\n",
      "        0.63330156]), 'mean_score_time': array([ 0.08247113,  0.08836492,  0.08854103,  0.07506045,  0.08148368,\n",
      "        0.07160568]), 'std_score_time': array([ 0.00582856,  0.00215699,  0.00328339,  0.00955051,  0.0092157 ,\n",
      "        0.01309228]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.9411399 ,  0.93977413,  0.93984006,  0.93642092,  0.93502689,\n",
      "        0.93497038]), 'split1_test_score': array([ 0.94172389,  0.94018857,  0.94012264,  0.93623254,  0.93575216,\n",
      "        0.93427336]), 'split2_test_score': array([ 0.94142192,  0.9402822 ,  0.94024452,  0.93642974,  0.93469661,\n",
      "        0.9355255 ]), 'mean_test_score': array([ 0.94142857,  0.94008163,  0.94006907,  0.93636107,  0.93515856,\n",
      "        0.93492308]), 'std_test_score': array([  2.38457829e-04,   2.20772260e-04,   1.69407922e-04,\n",
      "         9.09546851e-05,   4.40871311e-04,   5.12274999e-04]), 'rank_test_score': array([1, 2, 3, 4, 5, 6], dtype=int32), 'split0_train_score': array([ 0.99851177,  0.99946311,  0.99954788,  0.9994584 ,  0.99948195,\n",
      "        0.99950078]), 'split1_train_score': array([ 0.99844584,  0.99946311,  0.99952904,  0.99947253,  0.99942072,\n",
      "        0.99942072]), 'split2_train_score': array([ 0.99835636,  0.99937363,  0.99943956,  0.99909105,  0.99908164,\n",
      "        0.99938776]), 'mean_train_score': array([ 0.99843799,  0.99943328,  0.99950549,  0.99934066,  0.9993281 ,\n",
      "        0.99943642]), 'std_train_score': array([  6.36874138e-05,   4.21808698e-05,   4.72513330e-05,\n",
      "         1.76591666e-04,   1.76060555e-04,   4.74597372e-05])}\n",
      "0.941428571429\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 23315, 'Neg': 295185, 'TP': 20489, 'TN': 295140, 'FP': 45, 'FN': 2826, 'Accuracy': 0.99098587127158555, 'Precision': 0.99780851271062632, 'Recall': 0.87879047823289724, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=500,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 153.7122709 ,  119.03896705,  118.63339488,  118.26170746,\n",
      "        116.46984935,  120.05764413]), 'std_fit_time': array([ 24.14668856,   0.2753121 ,   0.05200523,   0.28374682,\n",
      "         0.52372332,   0.36162853]), 'mean_score_time': array([ 0.06972194,  0.07226841,  0.07326674,  0.071649  ,  0.0740308 ,\n",
      "        0.0683984 ]), 'std_score_time': array([ 0.00863639,  0.00849347,  0.00308593,  0.00332107,  0.00200955,\n",
      "        0.00749684]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.93397195,  0.94447427,  0.94385261,  0.94302373,  0.93875686,\n",
      "        0.93773018]), 'split1_test_score': array([ 0.93460303,  0.94454962,  0.94407867,  0.94352294,  0.93738167,\n",
      "        0.93785263]), 'split2_test_score': array([ 0.93443287,  0.94434188,  0.94391802,  0.94280655,  0.93858674,\n",
      "        0.93727747]), 'mean_test_score': array([ 0.93433595,  0.94445526,  0.94394976,  0.94311774,  0.93824176,\n",
      "        0.93762009]), 'std_test_score': array([  2.66597284e-04,   8.58703898e-05,   9.49796819e-05,\n",
      "         2.99925545e-04,   6.12126860e-04,   2.47373562e-04]), 'rank_test_score': array([6, 1, 2, 3, 4, 5], dtype=int32), 'split0_train_score': array([ 0.94140336,  0.99934537,  0.99954317,  0.99948195,  0.99950078,\n",
      "        0.99948195]), 'split1_train_score': array([ 0.94116788,  0.99932182,  0.99952904,  0.9994584 ,  0.99941601,\n",
      "        0.99943956]), 'split2_train_score': array([ 0.94147428,  0.99923705,  0.99942543,  0.99912402,  0.99936892,\n",
      "        0.99930769]), 'mean_train_score': array([ 0.94134851,  0.99930141,  0.99949922,  0.99935479,  0.99942857,\n",
      "        0.99940973]), 'std_train_score': array([  1.30962285e-04,   4.65150010e-05,   5.24894064e-05,\n",
      "         1.63459736e-04,   5.45614741e-05,   7.41983223e-05])}\n",
      "0.944455259027\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 23315, 'Neg': 295185, 'TP': 22938, 'TN': 295158, 'FP': 27, 'FN': 377, 'Accuracy': 0.9987315541601256, 'Precision': 0.99882429784454607, 'Recall': 0.98383015226249193, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='perceptron', max_iter=None,\n",
      "       n_iter=500, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 90.76893195,  91.43368729,  90.63098995,  91.44863605,\n",
      "        90.70893574,  89.2517244 ]), 'std_fit_time': array([ 0.86556079,  0.94625697,  0.85018436,  0.90710781,  0.74538001,\n",
      "        2.55746508]), 'mean_score_time': array([ 0.07405082,  0.06986562,  0.0702254 ,  0.06990949,  0.07049076,\n",
      "        0.06654668]), 'std_score_time': array([ 0.00510757,  0.00083477,  0.00065239,  0.00078051,  0.00089041,\n",
      "        0.00527744]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.93757005,  0.93888873,  0.93791856,  0.93722155,  0.93571449,\n",
      "        0.93436755]), 'split1_test_score': array([ 0.93838952,  0.93919014,  0.93806927,  0.93714619,  0.93599706,\n",
      "        0.93427336]), 'split2_test_score': array([ 0.93736224,  0.93863384,  0.93734341,  0.93736224,  0.9359682 ,\n",
      "        0.93396191]), 'mean_test_score': array([ 0.93777394,  0.93890424,  0.93777708,  0.93724333,  0.93589325,\n",
      "        0.93420094]), 'std_test_score': array([  4.43471080e-04,   2.27375439e-04,   3.12763925e-04,\n",
      "         8.95364796e-05,   1.26952087e-04,   1.73340235e-04]), 'rank_test_score': array([3, 1, 2, 4, 5, 6], dtype=int32), 'split0_train_score': array([ 0.99939717,  0.99947724,  0.99948195,  0.99949136,  0.99947724,\n",
      "        0.9995102 ]), 'split1_train_score': array([ 0.99943485,  0.99941601,  0.99943485,  0.9994584 ,  0.99943014,\n",
      "        0.99947724]), 'split2_train_score': array([ 0.99902041,  0.99919937,  0.99933595,  0.99937834,  0.99939247,\n",
      "        0.99935008]), 'mean_train_score': array([ 0.99928414,  0.99936421,  0.99941758,  0.9994427 ,  0.99943328,\n",
      "        0.99944584]), 'std_train_score': array([  1.87121070e-04,   1.19204386e-04,   6.08395834e-05,\n",
      "         4.74593992e-05,   3.46782444e-05,   6.90367887e-05])}\n",
      "0.938904238619\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 23315, 'Neg': 295185, 'TP': 23204, 'TN': 295025, 'FP': 160, 'FN': 111, 'Accuracy': 0.99914913657770799, 'Precision': 0.99315185755863722, 'Recall': 0.99523911644863816, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 2.05466509,  2.10858456,  2.10348233,  2.08972319,  2.09401417,\n",
      "        2.00858021]), 'std_fit_time': array([ 0.07633883,  0.00566139,  0.01582687,  0.00611023,  0.00863995,\n",
      "        0.10033596]), 'mean_score_time': array([ 0.22187567,  0.22184078,  0.2200613 ,  0.22049578,  0.21865726,\n",
      "        0.18386102]), 'std_score_time': array([ 0.00046108,  0.00123888,  0.00189998,  0.00134369,  0.00258676,\n",
      "        0.04580752]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.92998766,  0.93110854,  0.93132518,  0.93144762,  0.93150414,\n",
      "        0.93150414]), 'split1_test_score': array([ 0.92929065,  0.93021372,  0.93057165,  0.93067526,  0.93072235,\n",
      "        0.93076003]), 'split2_test_score': array([ 0.92896973,  0.929987  ,  0.93026016,  0.93039203,  0.93046738,\n",
      "        0.9304768 ]), 'mean_test_score': array([ 0.92941601,  0.93043642,  0.930719  ,  0.9308383 ,  0.93089796,\n",
      "        0.93091366]), 'std_test_score': array([ 0.00042492,  0.00048419,  0.0004471 ,  0.0004461 ,  0.00044109,\n",
      "        0.00043325]), 'rank_test_score': array([6, 5, 4, 3, 2, 1], dtype=int32), 'split0_train_score': array([ 0.98994504,  0.9903171 ,  0.9904678 ,  0.99053374,  0.99055729,\n",
      "        0.9905667 ]), 'split1_train_score': array([ 0.99028884,  0.99066561,  0.99077393,  0.99083044,  0.99088225,\n",
      "        0.99090108]), 'split2_train_score': array([ 0.98948826,  0.98995922,  0.99006283,  0.99011463,  0.99016644,\n",
      "        0.99016644]), 'mean_train_score': array([ 0.98990738,  0.99031397,  0.99043485,  0.99049294,  0.99053532,\n",
      "        0.99054474]), 'std_train_score': array([ 0.00032792,  0.00028839,  0.00029124,  0.00029365,  0.00029264,\n",
      "        0.00030032])}\n",
      "0.930913657771\n",
      "1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 23315, 'Neg': 295185, 'TP': 21981, 'TN': 290270, 'FP': 4915, 'FN': 1334, 'Accuracy': 0.98037990580847723, 'Precision': 0.8172590719809637, 'Recall': 0.94278361569804847, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 796.74052143,  783.09597953,  786.76948921,  801.73516504,\n",
      "        780.81312251,  766.24626756]), 'std_fit_time': array([  55.13912845,   51.91739963,  108.72137756,  109.6489624 ,\n",
      "         47.0497342 ,  116.50947606]), 'mean_score_time': array([ 0.07251445,  0.07413554,  0.07409064,  0.07221492,  0.07379405,\n",
      "        0.06659603]), 'std_score_time': array([ 0.00083559,  0.00146998,  0.00159353,  0.0011327 ,  0.0015348 ,\n",
      "        0.00718229]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.93337855,  0.93336913,  0.93338796,  0.93338796,  0.93338796,\n",
      "        0.93336913]), 'split1_test_score': array([ 0.93378357,  0.93377415,  0.93375531,  0.93377415,  0.93376473,\n",
      "        0.93376473]), 'split2_test_score': array([ 0.93352862,  0.93352862,  0.93351921,  0.93351921,  0.93352862,\n",
      "        0.93352862]), 'mean_test_score': array([ 0.93356358,  0.9335573 ,  0.93355416,  0.93356044,  0.93356044,\n",
      "        0.93355416]), 'std_test_score': array([ 0.00016719,  0.00016659,  0.00015199,  0.00016033,  0.00015545,\n",
      "        0.00016251]), 'rank_test_score': array([1, 4, 5, 2, 2, 5], dtype=int32), 'split0_train_score': array([ 0.99954317,  0.99954317,  0.99954317,  0.99954317,  0.99954317,\n",
      "        0.99954317]), 'split1_train_score': array([ 0.99954317,  0.99954317,  0.99954788,  0.99954317,  0.99954317,\n",
      "        0.99954317]), 'split2_train_score': array([ 0.99944898,  0.99944898,  0.99944898,  0.99945369,  0.99944898,\n",
      "        0.99944898]), 'mean_train_score': array([ 0.99951177,  0.99951177,  0.99951334,  0.99951334,  0.99951177,\n",
      "        0.99951177]), 'std_train_score': array([  4.44011560e-05,   4.44011560e-05,   4.55518104e-05,\n",
      "         4.21810475e-05,   4.44011560e-05,   4.44011560e-05])}\n",
      "0.933563579278\n",
      "1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 23315, 'Neg': 295185, 'TP': 23194, 'TN': 295118, 'FP': 67, 'FN': 121, 'Accuracy': 0.99940973312401882, 'Precision': 0.99711964231976269, 'Recall': 0.99481020802058762, 'desc': 'best'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier # mw\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "Cs = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# model = linear_model.SGDClassifier(loss='perceptron', max_iter=50) # max_iter 1000\n",
    "\n",
    "if isTraining:\n",
    "    mlp = MLPClassifier(random_state=0)\n",
    "    svm = linear_model.SGDClassifier(n_iter=500)\n",
    "    lgs = linear_model.SGDClassifier(loss='log', n_iter=500)\n",
    "    nbs = MultinomialNB()\n",
    "    rdg = linear_model.RidgeClassifier()\n",
    "    prc = linear_model.SGDClassifier(loss='perceptron', n_iter=500)\n",
    "    mList = [[svm,\"svm\"], [lgs,\"lgs\"], [prc,\"prc\"], [nbs,\"nbs\"], [rdg,\"rdg\"]]\n",
    "else:\n",
    "    mList = []\n",
    "\n",
    "for model in mList: \n",
    "# for model in []: \n",
    "# for model in [rdg]:    \n",
    "  fh = open(\"GridSearch.txt\", \"a\")\n",
    "  grid = GridSearchCV(estimator=model[0], param_grid=dict(alpha=alphas), n_jobs=2) #\n",
    "  grid.fit(X, y)\n",
    "  print(grid)\n",
    "  # summarize the results of the grid search\n",
    "  print(grid.cv_results_)\n",
    "  print(grid.best_score_)\n",
    "  print(grid.best_estimator_.alpha)\n",
    "\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(datetime.datetime.now()))\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(model[0]) + '\\n')  \n",
    "  fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "  fh.write(str(grid.best_score_) + '\\n')  \n",
    "  fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "  fh.close()\n",
    "\n",
    "  # MODEL: BEST\n",
    "  best = grid.best_estimator_\n",
    "\n",
    "  best.fit(X, y)\n",
    "  joblib.dump(best, 'best.{}.pkl'.format(model[1])) # pickle\n",
    "\n",
    "  best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "  best_performance.compute_measures()\n",
    "  print(best_performance.performance_measures)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.017822,
     "end_time": "2018-04-13T02:34:52.944192",
     "exception": false,
     "start_time": "2018-04-13T02:34:52.926370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npg = {\\'learning_rate\\': [\"constant\", \"invscaling\", \"adaptive\"],\\n\\'hidden_layer_sizes\\': [(100,1), (100,2), (100,3)],\\n#\\'alpha\\': [10.0 ** -np.arange(1, 7)],\\n\\'alpha\\': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\\n\\'activation\\': [\"logistic\", \"relu\", \"Tanh\"],\\n\\'tol\\': [1e-2, 1e-4, 1e-6],\\n\\'epsilon\\': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\\n}\\n\\nfh = open(\"GridSearch.txt\", \"a\")\\ngrid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\\ngrid.fit(X, y)\\nprint(grid)\\n# summarize the results of the grid search\\nprint(grid.cv_results_)\\nprint(grid.best_score_)\\nprint(grid.best_estimator_.alpha)\\n\\nfh.write(\\'\\n########\\n\\')\\nfh.write(str(datetime.datetime.now()))\\nfh.write(\\'\\n########\\n\\')\\nfh.write(str(model) + \\'\\n\\')  \\nfh.write(str(grid.cv_results_).replace(\", \\'\", \",\\n\\'\") + \\'\\n\\')\\nfh.write(str(grid.best_score_) + \\'\\n\\')  \\nfh.write(str(grid.best_estimator_.alpha) + \\'\\n\\')\\nfh.close()\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pg = {'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,1), (100,2), (100,3)],\n",
    "#'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"],\n",
    "'tol': [1e-2, 1e-4, 1e-6],\n",
    "'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\n",
    "}\n",
    "\n",
    "fh = open(\"GridSearch.txt\", \"a\")\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.cv_results_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(datetime.datetime.now()))\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(model) + '\\n')  \n",
    "fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "fh.write(str(grid.best_score_) + '\\n')  \n",
    "fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "fh.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.015548,
     "end_time": "2018-04-13T02:34:52.965738",
     "exception": false,
     "start_time": "2018-04-13T02:34:52.950190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# MODEL: BEST\\nbest = grid.best_estimator_\\n\\nbest.fit(X, y)\\njoblib.dump(best, 'best.pkl') # pickle\\n\\nbest_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\\nbest_performance.compute_measures()\\nprint(best_performance.performance_measures)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# MODEL: BEST\n",
    "best = grid.best_estimator_\n",
    "\n",
    "best.fit(X, y)\n",
    "joblib.dump(best, 'best.pkl') # pickle\n",
    "\n",
    "best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "best_performance.compute_measures()\n",
    "print(best_performance.performance_measures)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.2e-05,
     "end_time": "2018-04-13T02:34:52.973627",
     "exception": false,
     "start_time": "2018-04-13T02:34:52.973605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 0.074169,
     "end_time": "2018-04-13T02:34:53.068269",
     "exception": false,
     "start_time": "2018-04-13T02:34:52.994100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7af702198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if isTraining:\n",
    "    fList = []\n",
    "else:\n",
    "    fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "    fList = fits\n",
    "\n",
    "for fit in fList:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "if isTraining:\n",
    "    plt.title('ROC plot: training set')\n",
    "else:\n",
    "    plt.title('ROC plot: testing set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "duration": 12768.323318,
   "end_time": "2018-04-13T02:34:54.373298",
   "environment_variables": {},
   "exception": false,
   "output_path": "output.ipynb",
   "parameters": null,
   "start_time": "2018-04-12T23:02:06.049980",
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}