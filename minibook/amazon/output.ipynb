{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.001098,
     "end_time": "2018-03-08T12:56:46.378708",
     "exception": false,
     "start_time": "2018-03-08T12:56:46.377610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.79015,
     "end_time": "2018-03-08T12:56:47.175719",
     "exception": false,
     "start_time": "2018-03-08T12:56:46.385569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.027511,
     "end_time": "2018-03-08T12:56:47.203481",
     "exception": false,
     "start_time": "2018-03-08T12:56:47.175970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system('cp /home/wolfm2/job.sh .; echo test 1>&2') #; cp ../job.log ../jerbb.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.4e-05,
     "end_time": "2018-03-08T12:56:47.203614",
     "exception": false,
     "start_time": "2018-03-08T12:56:47.203600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 3.311254,
     "end_time": "2018-03-08T12:56:50.525161",
     "exception": false,
     "start_time": "2018-03-08T12:56:47.213907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.027801,
     "end_time": "2018-03-08T12:56:50.553213",
     "exception": false,
     "start_time": "2018-03-08T12:56:50.525412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      150581        487850  487851  B0025UCD76  A28B2M0XRXHXIG   \n",
      "1      334018         21518   21519  B002QWP89S   A7JJX3KMDZD2F   \n",
      "2       76657        319457  319458  B001GVIUX6  A2S8RJ6DRKGYON   \n",
      "3      357903        248851  248852  B0009JRH1C  A1FLQ698D9C0C8   \n",
      "4      301824        394613  394614  B001B4VOQI  A2KJO9EPX17ZXE   \n",
      "\n",
      "                   ProfileName  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "0                         B622                     0                       0   \n",
      "1  Shinichi Isozaki \"shincyan\"                     1                       2   \n",
      "2                   M. Ronning                     1                       2   \n",
      "3                     G. Zhang                     4                       8   \n",
      "4                    Musical E                     0                       0   \n",
      "\n",
      "   Score        Time                                            Summary  \\\n",
      "0      5  1313020800                                         DELICIOUS!   \n",
      "1      5  1268524800                     The pet dog is delighted, too!   \n",
      "2      2  1313798400  may be healthy but my \"eat anything\" cat won't...   \n",
      "3      5  1255478400                  Weight Loss Benefits of Green Tea   \n",
      "4      5  1305849600                     Healthy High Quality Dog Treat   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  This BBQ sauce is DELICIOUS!!  Sweet and tangy...        NaN    False  \n",
      "1  I gave a pet dog plural resemblance products, ...        0.5    False  \n",
      "2  I tried this in place of Iams.  My hefty maine...        0.5    False  \n",
      "3  Weight Loss Benefits of Green Tea<br />=======...        0.5    False  \n",
      "4  Yes, they are a bit expensive but, they are hi...        NaN    False  \n",
      "0.073206043956\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.4e-05,
     "end_time": "2018-03-08T12:56:50.553343",
     "exception": false,
     "start_time": "2018-03-08T12:56:50.553329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.014798,
     "end_time": "2018-03-08T12:56:50.578904",
     "exception": false,
     "start_time": "2018-03-08T12:56:50.564106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.012932,
     "end_time": "2018-03-08T12:56:50.591937",
     "exception": false,
     "start_time": "2018-03-08T12:56:50.579005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "#from nltk import word_tokenize          \n",
    "#from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "#class LemmaTokenizer(object):\n",
    "#     def __init__(self):\n",
    "#         self.wnl = WordNetLemmatizer()\n",
    "#     def __call__(self, doc):\n",
    "#         return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 62.21993,
     "end_time": "2018-03-08T12:57:52.811988",
     "exception": false,
     "start_time": "2018-03-08T12:56:50.592058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 1048576)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# tokenizer=LemmaTokenizer(),  analyzer=stemmed_words, stop_words={'english'}, \n",
    "hv = HashingVectorizer(n_features=2 ** 20, non_negative=True, strip_accents=ascii, \n",
    "                           ngram_range=(1,6), token_pattern = r'\\b[a-zA-Z]{3,}\\b')\n",
    "X_hv = hv.fit_transform(amazon.Text)\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.027961,
     "end_time": "2018-03-08T12:57:52.840204",
     "exception": false,
     "start_time": "2018-03-08T12:57:52.812243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv, 'hv.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 136.11642,
     "end_time": "2018-03-08T13:00:08.956766",
     "exception": false,
     "start_time": "2018-03-08T12:57:52.840346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.025551,
     "end_time": "2018-03-08T13:00:08.982545",
     "exception": false,
     "start_time": "2018-03-08T13:00:08.956994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 1.5e-05,
     "end_time": "2018-03-08T13:00:08.982700",
     "exception": false,
     "start_time": "2018-03-08T13:00:08.982685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.267419,
     "end_time": "2018-03-08T13:00:09.261829",
     "exception": false,
     "start_time": "2018-03-08T13:00:08.994410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen\n",
      "0      5        110\n",
      "1      5        140\n",
      "2      2        471\n",
      "3      5      10800\n",
      "4      5        152\n",
      "5      4        231\n",
      "6      5        271\n",
      "7      5        320\n",
      "8      2        362\n",
      "9      5        283\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.5e-05,
     "end_time": "2018-03-08T13:00:09.262107",
     "exception": false,
     "start_time": "2018-03-08T13:00:09.262092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 99.908121,
     "end_time": "2018-03-08T13:01:49.187356",
     "exception": false,
     "start_time": "2018-03-08T13:00:09.279235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 1048578)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.1e-05,
     "end_time": "2018-03-08T13:01:49.187749",
     "exception": false,
     "start_time": "2018-03-08T13:01:49.187738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 16.061919,
     "end_time": "2018-03-08T13:02:05.267316",
     "exception": false,
     "start_time": "2018-03-08T13:01:49.205397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 1048578)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1e-05,
     "end_time": "2018-03-08T13:02:05.267552",
     "exception": false,
     "start_time": "2018-03-08T13:02:05.267542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.029313,
     "end_time": "2018-03-08T13:02:05.314655",
     "exception": false,
     "start_time": "2018-03-08T13:02:05.285342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 9e-06,
     "end_time": "2018-03-08T13:02:05.314775",
     "exception": false,
     "start_time": "2018-03-08T13:02:05.314766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.024481,
     "end_time": "2018-03-08T13:02:05.357293",
     "exception": false,
     "start_time": "2018-03-08T13:02:05.332812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 13.251289,
     "end_time": "2018-03-08T13:02:18.608694",
     "exception": false,
     "start_time": "2018-03-08T13:02:05.357405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26379, 'TN': 337111, 'FP': 242, 'FN': 268, 'Accuracy': 0.99859890109890115, 'Precision': 0.99090943240299012, 'Recall': 0.9899425826547078, 'desc': 'svm'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: SVM, linear\n",
    "from sklearn import linear_model\n",
    "svm = linear_model.SGDClassifier()\n",
    "svm.fit(X, y)\n",
    "joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "svm_performance.compute_measures()\n",
    "print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 116.152237,
     "end_time": "2018-03-08T13:04:14.761150",
     "exception": false,
     "start_time": "2018-03-08T13:02:18.608913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26462, 'TN': 337226, 'FP': 127, 'FN': 185, 'Accuracy': 0.99914285714285711, 'Precision': 0.99522358870209482, 'Recall': 0.99305737981761544, 'desc': 'lgs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: logistic regression\n",
    "from sklearn import linear_model\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "lgs.fit(X, y)\n",
    "joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "lgs_performance.compute_measures()\n",
    "print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 9.651219,
     "end_time": "2018-03-08T13:04:24.412641",
     "exception": false,
     "start_time": "2018-03-08T13:04:14.761422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 23838, 'TN': 335296, 'FP': 2057, 'FN': 2809, 'Accuracy': 0.98663186813186809, 'Precision': 0.92056381540837995, 'Recall': 0.89458475625774003, 'desc': 'nbs'}\n"
     ]
    }
   ],
   "source": [
    "# MODEL: Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nbs = MultinomialNB()\n",
    "nbs.fit(X, y)\n",
    "joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "nbs_performance.compute_measures()\n",
    "print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL: Ridge Regression Classifier\n",
    "from sklearn import linear_model\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "rdg.fit(X, y)\n",
    "joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "\n",
    "rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "rdg_performance.compute_measures()\n",
    "print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL: Perceptron\n",
    "from sklearn import linear_model\n",
    "prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "prc.fit(X, y)\n",
    "joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "prc_performance.compute_measures()\n",
    "print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# model = linear_model.SGDClassifier(loss='perceptron', max_iter=50) # max_iter 1000\n",
    "\n",
    "svm = linear_model.SGDClassifier(n_iter=500)\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=500)\n",
    "nbs = MultinomialNB()\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "prc = linear_model.SGDClassifier(loss='perceptron', n_iter=500)\n",
    "\n",
    "for model in [svm, lgs, prc, nbs, rdg]: \n",
    "# for model in [rdg]:    \n",
    "  fh = open(\"GridSearch.txt\", \"a\")\n",
    "  grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas)) # n_jobs\n",
    "  grid.fit(X, y)\n",
    "  print(grid)\n",
    "  # summarize the results of the grid search\n",
    "  print(grid.cv_results_)\n",
    "  print(grid.best_score_)\n",
    "  print(grid.best_estimator_.alpha)\n",
    "\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(datetime.datetime.now()))\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(model) + '\\n')  \n",
    "  fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "  fh.write(str(grid.best_score_) + '\\n')  \n",
    "  fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "  fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "fits = [svm_performance, lgs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: training set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('cp /home/wolfm2/job.sh .; cp ../job.log ../jerbb.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "environment_variables": {},
   "output_path": "output.ipynb",
   "parameters": null,
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}