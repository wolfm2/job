{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.000509,
     "end_time": "2018-03-11T22:40:13.469500",
     "exception": false,
     "start_time": "2018-03-11T22:40:13.468991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.278721,
     "end_time": "2018-03-11T22:40:13.752217",
     "exception": false,
     "start_time": "2018-03-11T22:40:13.473496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.system('ps aux | grep wolfm2')\n",
    "os.system('killall -s SIGKILL -u wolfm2')\n",
    "#os.system('cp /home/wolfm2/job.sh .; echo test 1>&2') #; cp ../job.log ../jerbb.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "#  analyzer=stemmed_words,\n",
    "\n",
    "# look at the text prepended with other things we want to make into dummies.\n",
    "amazon['timeFilter'] = amazon['Time'].apply(lambda x: str(int(x)%(86400 * 7))) # converts to day of week\n",
    "hv0 = HashingVectorizer(n_features=2 ** 19, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,4), token_pattern = r'\\b[a-zA-Z]{3,}\\b')\n",
    "X_hv0 = hv0.fit_transform(amazon.timeFilter + \" \" + amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# and a second domain where we look at the summary\n",
    "amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "hv1 = HashingVectorizer(n_features=2 ** 18, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,4), token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b')\n",
    "X_hv1 = hv1.fit_transform(amazon.summaryFilter) \n",
    "# hv0 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv0 = hv0.fit_transform(amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "\n",
    "# hv1 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv1 = hv1.fit_transform(amazon.summaryFilter)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hv = sp.hstack([X_hv0, X_hv1], format='csr')\n",
    "\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = amazon.UserId + \" \" +  amazon.Text\n",
    "# x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv0, 'hv0.pkl') # pickle\n",
    "joblib.dump(hv1, 'hv1.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "amazon['summaryLen'] = amazon['summaryFilter'].str.len()\n",
    "#import zlib\n",
    "#amazon['nameHash'] = zlib.crc32(str(amazon['UserId']).encode('utf8'))\n",
    "#amazon['nameHash'] = amazon['UserId'].apply(lambda x: zlib.crc32(str(x).encode('utf8'))) # bad. don't do it this way\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\", \"summaryLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: SVM, linear\n",
    "# from sklearn import linear_model\n",
    "# svm = linear_model.SGDClassifier()\n",
    "# svm.fit(X, y)\n",
    "# joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "# svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "# svm_performance.compute_measures()\n",
    "# print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: logistic regression\n",
    "# from sklearn import linear_model\n",
    "# #lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "# lgs = linear_model.SGDClassifier(loss='log', n_iter=1000, alpha=0.1)\n",
    "\n",
    "# lgs.fit(X, y)\n",
    "# joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "# lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "# lgs_performance.compute_measures()\n",
    "# print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# nbs = MultinomialNB()\n",
    "# nbs.fit(X, y)\n",
    "# joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "# nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "# nbs_performance.compute_measures()\n",
    "# print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Ridge Regression Classifier\n",
    "# from sklearn import linear_model\n",
    "# rdg = linear_model.RidgeClassifier()\n",
    "# rdg.fit(X, y)\n",
    "# joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "\n",
    "# rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "# rdg_performance.compute_measures()\n",
    "# print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "# prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "# prc_performance.compute_measures()\n",
    "# print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# model = linear_model.SGDClassifier(loss='perceptron', max_iter=50) # max_iter 1000\n",
    "\n",
    "svm = linear_model.SGDClassifier(n_iter=1000)\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=1000)\n",
    "nbs = MultinomialNB()\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "prc = linear_model.SGDClassifier(loss='perceptron', n_iter=1000)\n",
    "\n",
    "for model in [svm, lgs, prc, nbs, rdg]: \n",
    "# for model in [rdg]:    \n",
    "  fh = open(\"GridSearch.txt\", \"a\")\n",
    "  grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas), n_jobs=2) #\n",
    "  grid.fit(X, y)\n",
    "  print(grid)\n",
    "  # summarize the results of the grid search\n",
    "  print(grid.cv_results_)\n",
    "  print(grid.best_score_)\n",
    "  print(grid.best_estimator_.alpha)\n",
    "\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(datetime.datetime.now()))\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(model) + '\\n')  \n",
    "  fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "  fh.write(str(grid.best_score_) + '\\n')  \n",
    "  fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "  fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL: BEST\n",
    "best = grid.best_estimator_\n",
    "\n",
    "best.fit(X, y)\n",
    "joblib.dump(best, 'best.pkl') # pickle\n",
    "\n",
    "best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "best_performance.compute_measures()\n",
    "print(best_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "# fits = [svm_performance, lgs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "# plt.title('ROC plot: training set')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "environment_variables": {},
   "output_path": "output.ipynb",
   "parameters": null,
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}