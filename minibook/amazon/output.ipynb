{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at 'In [23]'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.002408,
     "end_time": "2018-03-20T00:54:12.107710",
     "exception": false,
     "start_time": "2018-03-20T00:54:12.105302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.266229,
     "end_time": "2018-03-20T00:54:12.387823",
     "exception": false,
     "start_time": "2018-03-20T00:54:12.121594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.016065,
     "end_time": "2018-03-20T00:54:12.403978",
     "exception": false,
     "start_time": "2018-03-20T00:54:12.387913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.system('ps aux | grep wolfm2')\n",
    "#os.system('killall -s SIGKILL -u wolfm2')\n",
    "#os.system('cp /home/wolfm2/job.sh .; echo test 1>&2') #; cp ../job.log ../jerbb.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-20T00:54:12.404026",
     "exception": false,
     "start_time": "2018-03-20T00:54:12.404020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 1.63914,
     "end_time": "2018-03-20T00:54:14.051912",
     "exception": false,
     "start_time": "2018-03-20T00:54:12.412772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.011927,
     "end_time": "2018-03-20T00:54:14.063933",
     "exception": false,
     "start_time": "2018-03-20T00:54:14.052006",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      150581        487850  487851  B0025UCD76  A28B2M0XRXHXIG   \n",
      "1      334018         21518   21519  B002QWP89S   A7JJX3KMDZD2F   \n",
      "2       76657        319457  319458  B001GVIUX6  A2S8RJ6DRKGYON   \n",
      "3      357903        248851  248852  B0009JRH1C  A1FLQ698D9C0C8   \n",
      "4      301824        394613  394614  B001B4VOQI  A2KJO9EPX17ZXE   \n",
      "\n",
      "                   ProfileName  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "0                         B622                     0                       0   \n",
      "1  Shinichi Isozaki \"shincyan\"                     1                       2   \n",
      "2                   M. Ronning                     1                       2   \n",
      "3                     G. Zhang                     4                       8   \n",
      "4                    Musical E                     0                       0   \n",
      "\n",
      "   Score        Time                                            Summary  \\\n",
      "0      5  1313020800                                         DELICIOUS!   \n",
      "1      5  1268524800                     The pet dog is delighted, too!   \n",
      "2      2  1313798400  may be healthy but my \"eat anything\" cat won't...   \n",
      "3      5  1255478400                  Weight Loss Benefits of Green Tea   \n",
      "4      5  1305849600                     Healthy High Quality Dog Treat   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  This BBQ sauce is DELICIOUS!!  Sweet and tangy...        NaN    False  \n",
      "1  I gave a pet dog plural resemblance products, ...        0.5    False  \n",
      "2  I tried this in place of Iams.  My hefty maine...        0.5    False  \n",
      "3  Weight Loss Benefits of Green Tea<br />=======...        0.5    False  \n",
      "4  Yes, they are a bit expensive but, they are hi...        NaN    False  \n",
      "0.073206043956\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-20T00:54:14.064113",
     "exception": false,
     "start_time": "2018-03-20T00:54:14.064107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.010361,
     "end_time": "2018-03-20T00:54:14.084274",
     "exception": false,
     "start_time": "2018-03-20T00:54:14.073913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.200387,
     "end_time": "2018-03-20T00:54:14.284697",
     "exception": false,
     "start_time": "2018-03-20T00:54:14.084310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 334.025984,
     "end_time": "2018-03-20T00:59:48.310774",
     "exception": false,
     "start_time": "2018-03-20T00:54:14.284790",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 786432)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "#  analyzer=stemmed_words,\n",
    "\n",
    "# look at the text prepended with other things we want to make into dummies.\n",
    "amazon['timeFilter'] = amazon['Time'].apply(lambda x: str(int(x)%(86400 * 7))) # converts to day of week\n",
    "hv0 = HashingVectorizer(n_features=2 ** 19, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,3)) #, token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b')\n",
    "X_hv0 = hv0.fit_transform(amazon.timeFilter + \" \" + amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# and a second domain where we look at the summary\n",
    "amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "hv1 = HashingVectorizer(n_features=2 ** 18, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,3), token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b')\n",
    "X_hv1 = hv1.fit_transform(amazon.summaryFilter) \n",
    "\n",
    "\n",
    "\n",
    "# hv0 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv0 = hv0.fit_transform(amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "\n",
    "# hv1 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv1 = hv1.fit_transform(amazon.summaryFilter)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hv = sp.hstack([X_hv0, X_hv1], format='csr')\n",
    "\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.008807,
     "end_time": "2018-03-20T00:59:48.319676",
     "exception": false,
     "start_time": "2018-03-20T00:59:48.310869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = amazon.UserId + \" \" +  amazon.Text\n",
    "# x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.011787,
     "end_time": "2018-03-20T00:59:48.334052",
     "exception": false,
     "start_time": "2018-03-20T00:59:48.322265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv1.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv0, 'hv0.pkl') # pickle\n",
    "joblib.dump(hv1, 'hv1.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 12.633056,
     "end_time": "2018-03-20T01:00:00.967242",
     "exception": false,
     "start_time": "2018-03-20T00:59:48.334186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.009477,
     "end_time": "2018-03-20T01:00:00.976807",
     "exception": false,
     "start_time": "2018-03-20T01:00:00.967330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 8e-06,
     "end_time": "2018-03-20T01:00:00.979430",
     "exception": false,
     "start_time": "2018-03-20T01:00:00.979422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.221919,
     "end_time": "2018-03-20T01:00:01.211525",
     "exception": false,
     "start_time": "2018-03-20T01:00:00.989606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen  summaryLen\n",
      "0      5        110          10\n",
      "1      5        140          30\n",
      "2      2        471          55\n",
      "3      5      10800          33\n",
      "4      5        152          30\n",
      "5      4        231          60\n",
      "6      5        271          22\n",
      "7      5        320          19\n",
      "8      2        362          58\n",
      "9      5        283          16\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "amazon['summaryLen'] = amazon['summaryFilter'].str.len()\n",
    "#import zlib\n",
    "#amazon['nameHash'] = zlib.crc32(str(amazon['UserId']).encode('utf8'))\n",
    "#amazon['nameHash'] = amazon['UserId'].apply(lambda x: zlib.crc32(str(x).encode('utf8'))) # bad. don't do it this way\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\", \"summaryLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-20T01:00:01.211625",
     "exception": false,
     "start_time": "2018-03-20T01:00:01.211619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 21.361225,
     "end_time": "2018-03-20T01:00:22.582908",
     "exception": false,
     "start_time": "2018-03-20T01:00:01.221683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 786435)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-03-20T01:00:22.583011",
     "exception": false,
     "start_time": "2018-03-20T01:00:22.583004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.895167,
     "end_time": "2018-03-20T01:00:25.488507",
     "exception": false,
     "start_time": "2018-03-20T01:00:22.593340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 786435)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-03-20T01:00:25.488604",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.488597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.012735,
     "end_time": "2018-03-20T01:00:25.511896",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.499161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-20T01:00:25.512043",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.512037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.009138,
     "end_time": "2018-03-20T01:00:25.532230",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.523092",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 0.00919,
     "end_time": "2018-03-20T01:00:25.544296",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.535106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: SVM, linear\n",
    "# from sklearn import linear_model\n",
    "# svm = linear_model.SGDClassifier()\n",
    "# svm.fit(X, y)\n",
    "# joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "# svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "# svm_performance.compute_measures()\n",
    "# print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.012706,
     "end_time": "2018-03-20T01:00:25.560270",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.547564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: logistic regression\n",
    "# from sklearn import linear_model\n",
    "# #lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "# lgs = linear_model.SGDClassifier(loss='log', n_iter=1000, alpha=0.1)\n",
    "\n",
    "# lgs.fit(X, y)\n",
    "# joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "# lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "# lgs_performance.compute_measures()\n",
    "# print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.014717,
     "end_time": "2018-03-20T01:00:25.575021",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.560304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# nbs = MultinomialNB()\n",
    "# nbs.fit(X, y)\n",
    "# joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "# nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "# nbs_performance.compute_measures()\n",
    "# print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.012571,
     "end_time": "2018-03-20T01:00:25.587624",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.575053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Ridge Regression Classifier\n",
    "# from sklearn import linear_model\n",
    "# rdg = linear_model.RidgeClassifier()\n",
    "# rdg.fit(X, y)\n",
    "# joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "\n",
    "# rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "# rdg_performance.compute_measures()\n",
    "# print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.012633,
     "end_time": "2018-03-20T01:00:25.600290",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.587657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "# prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "# prc_performance.compute_measures()\n",
    "# print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 2495.125026,
     "end_time": "2018-03-20T01:42:00.725380",
     "exception": false,
     "start_time": "2018-03-20T01:00:25.600354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=1000,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 251.9200654 ,  243.60097599,  244.78087298,  243.93962153,\n",
      "        244.08013662,  243.96946104]), 'std_fit_time': array([ 1.64887144,  1.84023595,  1.23342146,  1.12046448,  0.93758519,\n",
      "        0.99741275]), 'mean_score_time': array([ 0.09974655,  0.10072414,  0.10139871,  0.0989329 ,  0.10132424,\n",
      "        0.09267926]), 'std_score_time': array([ 0.00068232,  0.00118959,  0.00035093,  0.00157224,  0.00022982,\n",
      "        0.01194632]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.94191241,  0.9412201 ,  0.94086571,  0.94040417,  0.93988495,\n",
      "        0.93840968]), 'split1_test_score': array([ 0.94258775,  0.94165643,  0.94116193,  0.94077456,  0.94042017,\n",
      "        0.93864818]), 'split2_test_score': array([ 0.94190369,  0.94120314,  0.9404861 ,  0.93965368,  0.93962896,\n",
      "        0.93801357]), 'mean_test_score': array([ 0.94213462,  0.94135989,  0.94083791,  0.94027747,  0.93997802,\n",
      "        0.93835714]), 'std_test_score': array([ 0.00032044,  0.0002098 ,  0.0002766 ,  0.00046629,  0.00032965,\n",
      "        0.00026173]), 'rank_test_score': array([1, 2, 3, 4, 5, 6], dtype=int32), 'split0_train_score': array([ 0.99935714,  0.99973626,  0.99989698,  0.99990522,  0.99990934,\n",
      "        0.9999011 ]), 'split1_train_score': array([ 0.99930769,  0.99974038,  0.9999217 ,  0.99992995,  0.99986401,\n",
      "        0.99987637]), 'split2_train_score': array([ 0.99928709,  0.99965385,  0.99984341,  0.99986813,  0.99978159,\n",
      "        0.99985577]), 'mean_train_score': array([ 0.99931731,  0.99971016,  0.99988736,  0.9999011 ,  0.99985165,\n",
      "        0.99987775]), 'std_train_score': array([  2.93956512e-05,   3.98585491e-05,   3.26795213e-05,\n",
      "         2.54027489e-05,   5.28799469e-05,   1.85310363e-05])}\n",
      "0.942134615385\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier # mw\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "Cs = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# model = linear_model.SGDClassifier(loss='perceptron', max_iter=50) # max_iter 1000\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "svm = linear_model.SGDClassifier(n_iter=1000)\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=1000)\n",
    "nbs = MultinomialNB()\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "prc = linear_model.SGDClassifier(loss='perceptron', n_iter=1000)\n",
    "\n",
    "#for model in [svm, lgs, prc, nbs, rdg]: \n",
    "for model in [svm]: \n",
    "# for model in [rdg]:    \n",
    "  fh = open(\"GridSearch.txt\", \"a\")\n",
    "  grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas), n_jobs=2) #\n",
    "  grid.fit(X, y)\n",
    "  print(grid)\n",
    "  # summarize the results of the grid search\n",
    "  print(grid.cv_results_)\n",
    "  print(grid.best_score_)\n",
    "  print(grid.best_estimator_.alpha)\n",
    "\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(datetime.datetime.now()))\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(model) + '\\n')  \n",
    "  fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "  fh.write(str(grid.best_score_) + '\\n')  \n",
    "  fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "  fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 4.788706,
     "end_time": "2018-03-20T01:42:05.514190",
     "exception": true,
     "start_time": "2018-03-20T01:42:00.725484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f24c4b94420, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f24c4b94420, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2ef074fd-e75464f4f3368ec2ea3cb82d']\n        msg = {'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2ef074fd-e75464f4f3368ec2ea3cb82d'], parent={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = False\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', silent=False, store_history=True, user_expressions={}, allow_stdin=False)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-23-1d0b8e82e417>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>\n        result = <ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>\n        self.user_global_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,\n         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd \\nimport m...t joblib\\nget_ipython().magic('matplotlib inline')\", \"import os \\nos.system('ps aux | grep wolfm2')\\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')\", \"amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\\nprint(amazon.shape)\", \"print(amazon.head())\\nprint(amazon['helpful'].mean())\", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\\n# print(X_bag_of_words.toarray())', \"import nltk\\n# nltk.download('punkt')\\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]\", \"# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\\n\\nprint(X_hv.shape)\", '# x = amazon.UserId + \" \" +  amazon.Text\\n# x.head(10)', \"# We want to be able to use this model fit on ot...l') # pickle\\njoblib.dump(hv1, 'hv1.pkl') # pickle\", \"# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle\", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\\nX_qu... # convert to sparse matrix\\nprint(X_matrix.shape)', \"# feature scaling\\nfrom sklearn.preprocessing imp...rint(X.shape)\\n\\njoblib.dump(sc, 'sc.pkl') # pickle\", \"y = amazon['helpful'].values\\nprint(type(y))\", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\\n# from sklearn import lin...s()\\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\\n# from sklearn im...s()\\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\\n# from sklearn.naive_baye...s()\\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,\n         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd \\nimport m...t joblib\\nget_ipython().magic('matplotlib inline')\", \"import os \\nos.system('ps aux | grep wolfm2')\\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')\", \"amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\\nprint(amazon.shape)\", \"print(amazon.head())\\nprint(amazon['helpful'].mean())\", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\\n# print(X_bag_of_words.toarray())', \"import nltk\\n# nltk.download('punkt')\\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]\", \"# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\\n\\nprint(X_hv.shape)\", '# x = amazon.UserId + \" \" +  amazon.Text\\n# x.head(10)', \"# We want to be able to use this model fit on ot...l') # pickle\\njoblib.dump(hv1, 'hv1.pkl') # pickle\", \"# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle\", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\\nX_qu... # convert to sparse matrix\\nprint(X_matrix.shape)', \"# feature scaling\\nfrom sklearn.preprocessing imp...rint(X.shape)\\n\\njoblib.dump(sc, 'sc.pkl') # pickle\", \"y = amazon['helpful'].values\\nprint(type(y))\", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\\n# from sklearn import lin...s()\\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\\n# from sklearn im...s()\\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\\n# from sklearn.naive_baye...s()\\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/wolfm2/jobout/minibook/amazon/<ipython-input-23-1d0b8e82e417> in <module>()\n      6 'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\n      7 }\n      8 \n      9 fh = open(\"GridSearch.txt\", \"a\")\n     10 grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\n---> 11 grid.fit(X, y)\n     12 print(grid)\n     13 # summarize the results of the grid search\n     14 print(grid.cv_results_)\n     15 print(grid.best_score_)\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y = array([False, False, False, ..., False, False, False], dtype=bool)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 19 21:42:04 2018\nPID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y_train = array([False, False, False, ..., False, False, False], dtype=bool)\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,\n       verbose=False, warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False))\n    387         if not isinstance(self.shuffle, bool):\n    388             raise ValueError(\"shuffle must be either True or False, got %s.\" %\n    389                              self.shuffle)\n    390         if self.max_iter <= 0:\n    391             raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_iter)\n--> 392         if self.alpha < 0.0:\n        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])\n    393             raise ValueError(\"alpha must be >= 0, got %s.\" % self.alpha)\n    394         if (self.learning_rate in [\"constant\", \"invscaling\", \"adaptive\"] and\n    395                 self.learning_rate_init <= 0.0):\n    396             raise ValueError(\"learning_rate_init must be > 0, got %s.\" %\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 973, in fit\n    hasattr(self, \"classes_\")))\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 326, in _fit\n    self._validate_hyperparameters()\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py\", line 392, in _validate_hyperparameters\n    if self.alpha < 0.0:\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/wolfm2/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Mar 19 21:42:04 2018\nPID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y_train = array([False, False, False, ..., False, False, False], dtype=bool)\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,\n       verbose=False, warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False))\n    387         if not isinstance(self.shuffle, bool):\n    388             raise ValueError(\"shuffle must be either True or False, got %s.\" %\n    389                              self.shuffle)\n    390         if self.max_iter <= 0:\n    391             raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_iter)\n--> 392         if self.alpha < 0.0:\n        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])\n    393             raise ValueError(\"alpha must be >= 0, got %s.\" % self.alpha)\n    394         if (self.learning_rate in [\"constant\", \"invscaling\", \"adaptive\"] and\n    395                 self.learning_rate_init <= 0.0):\n    396             raise ValueError(\"learning_rate_init must be > 0, got %s.\" %\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Mon Mar 19 21:42:04 2018\nPID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y_train = array([False, False, False, ..., False, False, False], dtype=bool)\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,\n       verbose=False, warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False))\n    387         if not isinstance(self.shuffle, bool):\n    388             raise ValueError(\"shuffle must be either True or False, got %s.\" %\n    389                              self.shuffle)\n    390         if self.max_iter <= 0:\n    391             raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_iter)\n--> 392         if self.alpha < 0.0:\n        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])\n    393             raise ValueError(\"alpha must be >= 0, got %s.\" % self.alpha)\n    394         if (self.learning_rate in [\"constant\", \"invscaling\", \"adaptive\"] and\n    395                 self.learning_rate_init <= 0.0):\n    396             raise ValueError(\"learning_rate_init must be > 0, got %s.\" %\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-1d0b8e82e417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GridSearch.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# summarize the results of the grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f24c4b94420, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f24c4b94420, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'2ef074fd-e75464f4f3368ec2ea3cb82d']\n        msg = {'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2ef074fd-e75464f4f3368ec2ea3cb82d'], parent={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = False\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', silent=False, store_history=True, user_expressions={}, allow_stdin=False)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='pg = {\\'learning_rate\\': [\"constant\", \"invscaling\"...tr(grid.best_estimator_.alpha) + \\'\\\\n\\')\\nfh.close()', store_history=True, silent=False, shell_futures=True)\n   2693                 self.displayhook.exec_result = result\n   2694 \n   2695                 # Execute the user code\n   2696                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2698                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2699                 \n   2700                 self.last_execution_succeeded = not has_raised\n   2701 \n   2702                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-23-1d0b8e82e417>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)\n   2797 \n   2798         try:\n   2799             for i, node in enumerate(to_run_exec):\n   2800                 mod = ast.Module([node])\n   2801                 code = compiler(mod, cell_name, \"exec\")\n-> 2802                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>\n        result = <ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>\n   2803                     return True\n   2804 \n   2805             for i, node in enumerate(to_run_interactive):\n   2806                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)\n   2857         outflag = True  # happens in more places, so it's easier as default\n   2858         try:\n   2859             try:\n   2860                 self.hooks.pre_run_code_hook()\n   2861                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f2475823030, file \"<ipython-input-23-1d0b8e82e417>\", line 11>\n        self.user_global_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,\n         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd \\nimport m...t joblib\\nget_ipython().magic('matplotlib inline')\", \"import os \\nos.system('ps aux | grep wolfm2')\\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')\", \"amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\\nprint(amazon.shape)\", \"print(amazon.head())\\nprint(amazon['helpful'].mean())\", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\\n# print(X_bag_of_words.toarray())', \"import nltk\\n# nltk.download('punkt')\\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]\", \"# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\\n\\nprint(X_hv.shape)\", '# x = amazon.UserId + \" \" +  amazon.Text\\n# x.head(10)', \"# We want to be able to use this model fit on ot...l') # pickle\\njoblib.dump(hv1, 'hv1.pkl') # pickle\", \"# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle\", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\\nX_qu... # convert to sparse matrix\\nprint(X_matrix.shape)', \"# feature scaling\\nfrom sklearn.preprocessing imp...rint(X.shape)\\n\\njoblib.dump(sc, 'sc.pkl') # pickle\", \"y = amazon['helpful'].values\\nprint(type(y))\", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\\n# from sklearn import lin...s()\\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\\n# from sklearn im...s()\\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\\n# from sklearn.naive_baye...s()\\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n        self.user_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,\n         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', \"import numpy as np\\nimport pandas as pd \\nimport m...t joblib\\nget_ipython().magic('matplotlib inline')\", \"import os \\nos.system('ps aux | grep wolfm2')\\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')\", \"amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\\nprint(amazon.shape)\", \"print(amazon.head())\\nprint(amazon['helpful'].mean())\", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\\n# print(X_bag_of_words.toarray())', \"import nltk\\n# nltk.download('punkt')\\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]\", \"# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\\n\\nprint(X_hv.shape)\", '# x = amazon.UserId + \" \" +  amazon.Text\\n# x.head(10)', \"# We want to be able to use this model fit on ot...l') # pickle\\njoblib.dump(hv1, 'hv1.pkl') # pickle\", \"# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle\", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\\nX_qu... # convert to sparse matrix\\nprint(X_matrix.shape)', \"# feature scaling\\nfrom sklearn.preprocessing imp...rint(X.shape)\\n\\njoblib.dump(sc, 'sc.pkl') # pickle\", \"y = amazon['helpful'].values\\nprint(type(y))\", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\\n# from sklearn import lin...s()\\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\\n# from sklearn im...s()\\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\\n# from sklearn.naive_baye...s()\\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}\n   2863             finally:\n   2864                 # Reset our crash handler in place\n   2865                 sys.excepthook = old_excepthook\n   2866         except SystemExit as e:\n\n...........................................................................\n/home/wolfm2/jobout/minibook/amazon/<ipython-input-23-1d0b8e82e417> in <module>()\n      6 'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\n      7 }\n      8 \n      9 fh = open(\"GridSearch.txt\", \"a\")\n     10 grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\n---> 11 grid.fit(X, y)\n     12 print(grid)\n     13 # summarize the results of the grid search\n     14 print(grid.cv_results_)\n     15 print(grid.best_score_)\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',\n     ...ain_score='warn',\n       scoring=None, verbose=0), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>\n        X = <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y = array([False, False, False, ..., False, False, False], dtype=bool)\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Mon Mar 19 21:42:04 2018\nPID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>\n        y_train = array([False, False, False, ..., False, False, False], dtype=bool)\n        fit_params = {}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))\n    968         Returns\n    969         -------\n    970         self : returns a trained MLP model.\n    971         \"\"\"\n    972         return self._fit(X, y, incremental=(self.warm_start and\n--> 973                                             hasattr(self, \"classes_\")))\n        self = MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False)\n    974 \n    975     @property\n    976     def partial_fit(self):\n    977         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)\n    321         if not hasattr(hidden_layer_sizes, \"__iter__\"):\n    322             hidden_layer_sizes = [hidden_layer_sizes]\n    323         hidden_layer_sizes = list(hidden_layer_sizes)\n    324 \n    325         # Validate input parameters.\n--> 326         self._validate_hyperparameters()\n        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,\n       verbose=False, warm_start=False)>\n    327         if np.any(np.array(hidden_layer_sizes) <= 0):\n    328             raise ValueError(\"hidden_layer_sizes must be > 0, got %s.\" %\n    329                              hidden_layer_sizes)\n    330 \n\n...........................................................................\n/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',\n       alph...tion=0.1,\n       verbose=False, warm_start=False))\n    387         if not isinstance(self.shuffle, bool):\n    388             raise ValueError(\"shuffle must be either True or False, got %s.\" %\n    389                              self.shuffle)\n    390         if self.max_iter <= 0:\n    391             raise ValueError(\"max_iter must be > 0, got %s.\" % self.max_iter)\n--> 392         if self.alpha < 0.0:\n        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])\n    393             raise ValueError(\"alpha must be >= 0, got %s.\" % self.alpha)\n    394         if (self.learning_rate in [\"constant\", \"invscaling\", \"adaptive\"] and\n    395                 self.learning_rate_init <= 0.0):\n    396             raise ValueError(\"learning_rate_init must be > 0, got %s.\" %\n\nValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "pg = {'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,1), (100,2), (100,3)],\n",
    "'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"],\n",
    "'tol': [1e-2, 1e-4, 1e-6],\n",
    "'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\n",
    "}\n",
    "\n",
    "fh = open(\"GridSearch.txt\", \"a\")\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.cv_results_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(datetime.datetime.now()))\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(model) + '\\n')  \n",
    "fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "fh.write(str(grid.best_score_) + '\\n')  \n",
    "fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL: BEST\n",
    "best = grid.best_estimator_\n",
    "\n",
    "best.fit(X, y)\n",
    "joblib.dump(best, 'best.pkl') # pickle\n",
    "\n",
    "best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "best_performance.compute_measures()\n",
    "print(best_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "# fits = [svm_performance, lgs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "# plt.title('ROC plot: training set')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "duration": 2875.740935,
   "end_time": "2018-03-20T01:42:07.104171",
   "environment_variables": {},
   "exception": true,
   "output_path": "output.ipynb",
   "parameters": null,
   "start_time": "2018-03-20T00:54:11.363236",
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}