
Mon Mar 19 20:54:02 EDT 2018
Doing...
Updating ed85313..72b5736
Fast-forward
 minibook/amazon/_01_train.ipynb | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)
sending incremental file list
deleting __pycache__/my_measures.cpython-36.pyc
deleting __pycache__/
deleting transformer.pkl
deleting sc.pkl
deleting output.ipynb
deleting job.log
deleting hv1.pkl
deleting hv0.pkl
deleting Amazon.csv
./
_01_train.ipynb

sent 61,818 bytes  received 188 bytes  124,012.00 bytes/sec
total size is 149,516  speedup is 2.41
Amazon.csv

bzip2: (stdin): trailing garbage after EOF ignored
cat: write error: Broken pipe
  0%|          | 0/34 [00:00<?, ?it/s]  6%|▌         | 2/34 [00:00<00:04,  6.94it/s]wolfm2   28288  0.0  0.0   4504   708 ?        Ss   20:54   0:00 /bin/sh -c /home/wolfm2/job.sh
wolfm2   28290  0.0  0.0  12544  2984 ?        S    20:54   0:00 /bin/bash /home/wolfm2/job.sh
wolfm2   28317  8.8  0.3 715080 107712 ?       Sl   20:54   0:00 /home/wolfm2/anaconda3/bin/python /home/wolfm2/jobin/main.py
wolfm2   28357 73.0  0.3 980976 116020 ?       Ssl  20:54   0:00 /home/wolfm2/anaconda3/bin/python -m ipykernel_launcher -f /tmp/tmp1wfjibor.json
wolfm2   28384  0.0  0.0   4504   788 ?        S    20:54   0:00 sh -c ps aux | grep wolfm2
wolfm2   28385  0.0  0.0  37364  3228 ?        R    20:54   0:00 ps aux
wolfm2   28386  0.0  0.0  14224  1084 ?        S    20:54   0:00 grep wolfm2
 15%|█▍        | 5/34 [00:01<00:11,  2.56it/s] 26%|██▋       | 9/34 [00:02<00:06,  4.12it/s] 29%|██▉       | 10/34 [05:36<13:26, 33.62s/it] 38%|███▊      | 13/34 [05:48<09:23, 26.84s/it] 47%|████▋     | 16/34 [05:49<06:32, 21.82s/it] 53%|█████▎    | 18/34 [06:10<05:29, 20.58s/it] 59%|█████▉    | 20/34 [06:13<04:21, 18.67s/it] 85%|████████▌ | 29/34 [06:13<01:04, 12.88s/it] 85%|████████▌ | 29/34 [06:30<01:07, 13.46s/it] 88%|████████▊ | 30/34 [47:48<06:22, 95.62s/it]Input Notebook:  _01_train.ipynb
Output Notebook: output.ipynb
Traceback (most recent call last):
  File "/home/wolfm2/jobin/main.py", line 78, in <module>
    main()
  File "/home/wolfm2/jobin/main.py", line 18, in main
    'output.ipynb',
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/papermill/execute.py", line 197, in execute_notebook
    raise_for_execution_errors(nb, output)
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/papermill/execute.py", line 394, in raise_for_execution_errors
    raise error
papermill.exceptions.PapermillExecutionError: 
---------------------------------------------------------------------------
Exception encountered at "In [23]":
---------------------------------------------------------------------------
RemoteTraceback                           Traceback (most recent call last)
RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 350, in __call__
    return self.func(*args, **kwargs)
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 458, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py", line 973, in fit
    hasattr(self, "classes_")))
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py", line 326, in _fit
    self._validate_hyperparameters()
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py", line 392, in _validate_hyperparameters
    if self.alpha < 0.0:
ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/wolfm2/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 359, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Mon Mar 19 21:42:04 2018
PID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python
...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')
    453 
    454     try:
    455         if y_train is None:
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,
       verbose=False, warm_start=False)>
        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>
        y_train = array([False, False, False, ..., False, False, False], dtype=bool)
        fit_params = {}
    459 
    460     except Exception as e:
    461         # Note fit time as time until error
    462         fit_time = time.time() - start_time

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))
    968         Returns
    969         -------
    970         self : returns a trained MLP model.
    971         """
    972         return self._fit(X, y, incremental=(self.warm_start and
--> 973                                             hasattr(self, "classes_")))
        self = MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False)
    974 
    975     @property
    976     def partial_fit(self):
    977         """Fit the model to data matrix X and target y.

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)
    321         if not hasattr(hidden_layer_sizes, "__iter__"):
    322             hidden_layer_sizes = [hidden_layer_sizes]
    323         hidden_layer_sizes = list(hidden_layer_sizes)
    324 
    325         # Validate input parameters.
--> 326         self._validate_hyperparameters()
        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,
       verbose=False, warm_start=False)>
    327         if np.any(np.array(hidden_layer_sizes) <= 0):
    328             raise ValueError("hidden_layer_sizes must be > 0, got %s." %
    329                              hidden_layer_sizes)
    330 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False))
    387         if not isinstance(self.shuffle, bool):
    388             raise ValueError("shuffle must be either True or False, got %s." %
    389                              self.shuffle)
    390         if self.max_iter <= 0:
    391             raise ValueError("max_iter must be > 0, got %s." % self.max_iter)
--> 392         if self.alpha < 0.0:
        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])
    393             raise ValueError("alpha must be >= 0, got %s." % self.alpha)
    394         if (self.learning_rate in ["constant", "invscaling", "adaptive"] and
    395                 self.learning_rate_init <= 0.0):
    396             raise ValueError("learning_rate_init must be > 0, got %s." %

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

TransportableException                    Traceback (most recent call last)
~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in retrieve(self)
    698                 if getattr(self._backend, 'supports_timeout', False):
--> 699                     self._output.extend(job.get(timeout=self.timeout))
    700                 else:

~/anaconda3/lib/python3.6/multiprocessing/pool.py in get(self, timeout)
    643         else:
--> 644             raise self._value
    645 

TransportableException: TransportableException
___________________________________________________________________________
ValueError                                         Mon Mar 19 21:42:04 2018
PID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python
...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')
    453 
    454     try:
    455         if y_train is None:
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,
       verbose=False, warm_start=False)>
        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>
        y_train = array([False, False, False, ..., False, False, False], dtype=bool)
        fit_params = {}
    459 
    460     except Exception as e:
    461         # Note fit time as time until error
    462         fit_time = time.time() - start_time

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))
    968         Returns
    969         -------
    970         self : returns a trained MLP model.
    971         """
    972         return self._fit(X, y, incremental=(self.warm_start and
--> 973                                             hasattr(self, "classes_")))
        self = MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False)
    974 
    975     @property
    976     def partial_fit(self):
    977         """Fit the model to data matrix X and target y.

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)
    321         if not hasattr(hidden_layer_sizes, "__iter__"):
    322             hidden_layer_sizes = [hidden_layer_sizes]
    323         hidden_layer_sizes = list(hidden_layer_sizes)
    324 
    325         # Validate input parameters.
--> 326         self._validate_hyperparameters()
        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,
       verbose=False, warm_start=False)>
    327         if np.any(np.array(hidden_layer_sizes) <= 0):
    328             raise ValueError("hidden_layer_sizes must be > 0, got %s." %
    329                              hidden_layer_sizes)
    330 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False))
    387         if not isinstance(self.shuffle, bool):
    388             raise ValueError("shuffle must be either True or False, got %s." %
    389                              self.shuffle)
    390         if self.max_iter <= 0:
    391             raise ValueError("max_iter must be > 0, got %s." % self.max_iter)
--> 392         if self.alpha < 0.0:
        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])
    393             raise ValueError("alpha must be >= 0, got %s." % self.alpha)
    394         if (self.learning_rate in ["constant", "invscaling", "adaptive"] and
    395                 self.learning_rate_init <= 0.0):
    396             raise ValueError("learning_rate_init must be > 0, got %s." %

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
___________________________________________________________________________

During handling of the above exception, another exception occurred:

JoblibValueError                          Traceback (most recent call last)
<ipython-input-23-1d0b8e82e417> in <module>()
      9 fh = open("GridSearch.txt", "a")
     10 grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #
---> 11 grid.fit(X, y)
     12 print(grid)
     13 # summarize the results of the grid search

~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self, X, y, groups, **fit_params)
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
    640 
    641         # if one choose to see train score, "out" will contain train score info

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    787                 # consumption.
    788                 self._iterating = False
--> 789             self.retrieve()
    790             # Make sure that we get a last message telling us we are done
    791             elapsed_time = time.time() - self._start_time

~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in retrieve(self)
    738                     exception = exception_type(report)
    739 
--> 740                     raise exception
    741 
    742     def __call__(self, iterable):

JoblibValueError: JoblibValueError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)
    188         sys.exit(msg)
    189     main_globals = sys.modules["__main__"].__dict__
    190     if alter_argv:
    191         sys.argv[0] = mod_spec.origin
    192     return _run_code(code, main_globals, None,
--> 193                      "__main__", mod_spec)
        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')
    194 
    195 def run_module(mod_name, init_globals=None,
    196                run_name=None, alter_sys=False):
    197     """Execute a module's code without importing it

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f24c4b94420, file "/...3.6/site-packages/ipykernel_launcher.py", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\n\nTh...orts until\nafter removing the cwd from sys.path.\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)
     80                        __cached__ = cached,
     81                        __doc__ = None,
     82                        __loader__ = loader,
     83                        __package__ = pkg_name,
     84                        __spec__ = mod_spec)
---> 85     exec(code, run_globals)
        code = <code object <module> at 0x7f24c4b94420, file "/...3.6/site-packages/ipykernel_launcher.py", line 5>
        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\n\nTh...orts until\nafter removing the cwd from sys.path.\n', '__file__': '/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/home/wolfm2.../python3.6/site-packages/ipykernel/kernelapp.py'>, ...}
     86     return run_globals
     87 
     88 def _run_module_code(code, init_globals=None,
     89                     mod_name=None, mod_spec=None,

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()
     11     # This is added back by InteractiveShellApp.init_path()
     12     if sys.path[0] == '':
     13         del sys.path[0]
     14 
     15     from ipykernel import kernelapp as app
---> 16     app.launch_new_instance()

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})
    653 
    654         If a global instance already exists, this reinitializes and starts it
    655         """
    656         app = cls.instance(**kwargs)
    657         app.initialize(argv)
--> 658         app.start()
        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>
    659 
    660 #-----------------------------------------------------------------------------
    661 # utility functions, for convenience
    662 #-----------------------------------------------------------------------------

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)
    472             return self.subapp.start()
    473         if self.poller is not None:
    474             self.poller.start()
    475         self.kernel.start()
    476         try:
--> 477             ioloop.IOLoop.instance().start()
    478         except KeyboardInterrupt:
    479             pass
    480 
    481 launch_new_instance = IPKernelApp.launch_instance

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)
    172             )
    173         return loop
    174     
    175     def start(self):
    176         try:
--> 177             super(ZMQIOLoop, self).start()
        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>
    178         except ZMQError as e:
    179             if e.errno == ETERM:
    180                 # quietly return on ETERM
    181                 pass

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)
    883                 self._events.update(event_pairs)
    884                 while self._events:
    885                     fd, events = self._events.popitem()
    886                     try:
    887                         fd_obj, handler_func = self._handlers[fd]
--> 888                         handler_func(fd_obj, events)
        handler_func = <function wrap.<locals>.null_wrapper>
        fd_obj = <zmq.sugar.socket.Socket object>
        events = 1
    889                     except (OSError, IOError) as e:
    890                         if errno_from_exception(e) == errno.EPIPE:
    891                             # Happens when the client closes the connection
    892                             pass

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})
    272         # Fast path when there are no active contexts.
    273         def null_wrapper(*args, **kwargs):
    274             try:
    275                 current_state = _state.contexts
    276                 _state.contexts = cap_contexts[0]
--> 277                 return fn(*args, **kwargs)
        args = (<zmq.sugar.socket.Socket object>, 1)
        kwargs = {}
    278             finally:
    279                 _state.contexts = current_state
    280         null_wrapper._wrapped = True
    281         return null_wrapper

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)
    435             # dispatch events:
    436             if events & IOLoop.ERROR:
    437                 gen_log.error("got POLLERR event on ZMQStream, which doesn't make sense")
    438                 return
    439             if events & IOLoop.READ:
--> 440                 self._handle_recv()
        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>
    441                 if not self.socket:
    442                     return
    443             if events & IOLoop.WRITE:
    444                 self._handle_send()

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)
    467                 gen_log.error("RECV Error: %s"%zmq.strerror(e.errno))
    468         else:
    469             if self._recv_callback:
    470                 callback = self._recv_callback
    471                 # self._recv_callback = None
--> 472                 self._run_callback(callback, msg)
        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>
        callback = <function wrap.<locals>.null_wrapper>
        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]
    473                 
    474         # self.update_state()
    475         
    476 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})
    409         close our socket."""
    410         try:
    411             # Use a NullContext to ensure that all StackContexts are run
    412             # inside our blanket exception handler rather than outside.
    413             with stack_context.NullContext():
--> 414                 callback(*args, **kwargs)
        callback = <function wrap.<locals>.null_wrapper>
        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)
        kwargs = {}
    415         except:
    416             gen_log.error("Uncaught exception, closing connection.",
    417                           exc_info=True)
    418             # Close the socket on an uncaught exception from a user callback

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})
    272         # Fast path when there are no active contexts.
    273         def null_wrapper(*args, **kwargs):
    274             try:
    275                 current_state = _state.contexts
    276                 _state.contexts = cap_contexts[0]
--> 277                 return fn(*args, **kwargs)
        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)
        kwargs = {}
    278             finally:
    279                 _state.contexts = current_state
    280         null_wrapper._wrapped = True
    281         return null_wrapper

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])
    278         if self.control_stream:
    279             self.control_stream.on_recv(self.dispatch_control, copy=False)
    280 
    281         def make_dispatcher(stream):
    282             def dispatcher(msg):
--> 283                 return self.dispatch_shell(stream, msg)
        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]
    284             return dispatcher
    285 
    286         for s in self.shell_streams:
    287             s.on_recv(make_dispatcher(s), copy=False)

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})
    230             self.log.warn("Unknown message type: %r", msg_type)
    231         else:
    232             self.log.debug("%s: %s", msg_type, msg)
    233             self.pre_handler_hook()
    234             try:
--> 235                 handler(stream, idents, msg)
        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>
        stream = <zmq.eventloop.zmqstream.ZMQStream object>
        idents = [b'2ef074fd-e75464f4f3368ec2ea3cb82d']
        msg = {'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}}
    236             except Exception:
    237                 self.log.error("Exception in message handler:", exc_info=True)
    238             finally:
    239                 self.post_handler_hook()

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'2ef074fd-e75464f4f3368ec2ea3cb82d'], parent={'buffers': [], 'content': {'allow_stdin': False, 'code': 'pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 3, 20, 1, 42, 0, 725510, tzinfo=tzutc()), 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'session': '2ef074fd-e75464f4f3368ec2ea3cb82d', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b317ab13-8dd5bdb78a0a8cfd3c25bddd', 'msg_type': 'execute_request', 'parent_header': {}})
    394         if not silent:
    395             self.execution_count += 1
    396             self._publish_execute_input(code, parent, self.execution_count)
    397 
    398         reply_content = self.do_execute(code, silent, store_history,
--> 399                                         user_expressions, allow_stdin)
        user_expressions = {}
        allow_stdin = False
    400 
    401         # Flush output before sending the reply.
    402         sys.stdout.flush()
    403         sys.stderr.flush()

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()', silent=False, store_history=True, user_expressions={}, allow_stdin=False)
    191 
    192         self._forward_input(allow_stdin)
    193 
    194         reply_content = {}
    195         try:
--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)
        res = undefined
        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>
        code = 'pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()'
        store_history = True
        silent = False
    197         finally:
    198             self._restore_input()
    199 
    200         if res.error_before_exec is not None:

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()',), **kwargs={'silent': False, 'store_history': True})
    528             )
    529         self.payload_manager.write_payload(payload)
    530 
    531     def run_cell(self, *args, **kwargs):
    532         self._last_traceback = None
--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>
        args = ('pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()',)
        kwargs = {'silent': False, 'store_history': True}
    534 
    535     def _showtraceback(self, etype, evalue, stb):
    536         # try to preserve ordering of tracebacks and print statements
    537         sys.stdout.flush()

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='pg = {\'learning_rate\': ["constant", "invscaling"...tr(grid.best_estimator_.alpha) + \'\\n\')\nfh.close()', store_history=True, silent=False, shell_futures=True)
   2693                 self.displayhook.exec_result = result
   2694 
   2695                 # Execute the user code
   2696                 interactivity = "none" if silent else self.ast_node_interactivity
   2697                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,
-> 2698                    interactivity=interactivity, compiler=compiler, result=result)
        interactivity = 'last_expr'
        compiler = <IPython.core.compilerop.CachingCompiler object>
   2699                 
   2700                 self.last_execution_succeeded = not has_raised
   2701 
   2702                 # Reset this so later displayed values do not modify the

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-23-1d0b8e82e417>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)
   2797 
   2798         try:
   2799             for i, node in enumerate(to_run_exec):
   2800                 mod = ast.Module([node])
   2801                 code = compiler(mod, cell_name, "exec")
-> 2802                 if self.run_code(code, result):
        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>
        code = <code object <module> at 0x7f2475823030, file "<ipython-input-23-1d0b8e82e417>", line 11>
        result = <ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>
   2803                     return True
   2804 
   2805             for i, node in enumerate(to_run_interactive):
   2806                 mod = ast.Interactive([node])

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f2475823030, file "<ipython-input-23-1d0b8e82e417>", line 11>, result=<ExecutionResult object at 7f2479dc8be0, executi..._before_exec=None error_in_exec=None result=None>)
   2857         outflag = True  # happens in more places, so it's easier as default
   2858         try:
   2859             try:
   2860                 self.hooks.pre_run_code_hook()
   2861                 #rprint('Running code', repr(code_obj)) # dbg
-> 2862                 exec(code_obj, self.user_global_ns, self.user_ns)
        code_obj = <code object <module> at 0x7f2475823030, file "<ipython-input-23-1d0b8e82e417>", line 11>
        self.user_global_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,
         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', "import numpy as np\nimport pandas as pd \nimport m...t joblib\nget_ipython().magic('matplotlib inline')", "import os \nos.system('ps aux | grep wolfm2')\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')", "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\nprint(amazon.shape)", "print(amazon.head())\nprint(amazon['helpful'].mean())", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\n# print(X_bag_of_words.toarray())', "import nltk\n# nltk.download('punkt')\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]", "# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\n\nprint(X_hv.shape)", '# x = amazon.UserId + " " +  amazon.Text\n# x.head(10)', "# We want to be able to use this model fit on ot...l') # pickle\njoblib.dump(hv1, 'hv1.pkl') # pickle", "# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\nX_qu... # convert to sparse matrix\nprint(X_matrix.shape)', "# feature scaling\nfrom sklearn.preprocessing imp...rint(X.shape)\n\njoblib.dump(sc, 'sc.pkl') # pickle", "y = amazon['helpful'].values\nprint(type(y))", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\n# from sklearn import lin...s()\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\n# from sklearn im...s()\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\n# from sklearn.naive_baye...s()\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}
        self.user_ns = {'BinaryClassificationPerformance': <class 'my_measures.BinaryClassificationPerformance'>, 'Cs': array([  1.00000000e-03,   1.00000000e-02,   1.0...e+01,   1.00000000e+02,
         1.00000000e+03]), 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'HashingVectorizer': <class 'sklearn.feature_extraction.text.HashingVectorizer'>, 'In': ['', "import numpy as np\nimport pandas as pd \nimport m...t joblib\nget_ipython().magic('matplotlib inline')", "import os \nos.system('ps aux | grep wolfm2')\n#os... echo test 1>&2') #; cp ../job.log ../jerbb.txt')", "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\nprint(amazon.shape)", "print(amazon.head())\nprint(amazon['helpful'].mean())", '# # http://scikit-learn.org/stable/modules/gener...ansform(corpus)\n# print(X_bag_of_words.toarray())', "import nltk\n# nltk.download('punkt')\n# nltk.down...elf.wnl.lemmatize(t) for t in word_tokenize(doc)]", "# vectorize Bag of Words from review text; as sp...([X_hv0, X_hv1], format='csr')\n\nprint(X_hv.shape)", '# x = amazon.UserId + " " +  amazon.Text\n# x.head(10)', "# We want to be able to use this model fit on ot...l') # pickle\njoblib.dump(hv1, 'hv1.pkl') # pickle", "# http://scikit-learn.org/stable/modules/generat...lib.dump(transformer, 'transformer.pkl') # pickle", 'print(type(X_tfidf))', '# features from Amazon.csv to add to feature set..._features.head(10))\nprint(type(X_quant_features))', 'from scipy.sparse import csr_matrix, hstack\nX_qu... # convert to sparse matrix\nprint(X_matrix.shape)', "# feature scaling\nfrom sklearn.preprocessing imp...rint(X.shape)\n\njoblib.dump(sc, 'sc.pkl') # pickle", "y = amazon['helpful'].values\nprint(type(y))", 'from my_measures import BinaryClassificationPerformance', '# # MODEL: SVM, linear\n# from sklearn import lin...s()\n# print(svm_performance.performance_measures)', '# # MODEL: logistic regression\n# from sklearn im...s()\n# print(lgs_performance.performance_measures)', '# # MODEL: Naive Bayes\n# from sklearn.naive_baye...s()\n# print(nbs_performance.performance_measures)', ...], 'LemmaTokenizer': <class '__main__.LemmaTokenizer'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'Out': {2: 0, 9: ['hv1.pkl'], 10: ['transformer.pkl'], 14: ['sc.pkl']}, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, ...}
   2863             finally:
   2864                 # Reset our crash handler in place
   2865                 sys.excepthook = old_excepthook
   2866         except SystemExit as e:

...........................................................................
/home/wolfm2/jobout/minibook/amazon/<ipython-input-23-1d0b8e82e417> in <module>()
      6 'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]
      7 }
      8 
      9 fh = open("GridSearch.txt", "a")
     10 grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #
---> 11 grid.fit(X, y)
     12 print(grid)
     13 # summarize the results of the grid search
     14 print(grid.cv_results_)
     15 print(grid.best_score_)

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=None, error_score='raise',
     ...ain_score='warn',
       scoring=None, verbose=0), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), groups=None, **fit_params={})
    634                                   return_train_score=self.return_train_score,
    635                                   return_n_test_samples=True,
    636                                   return_times=True, return_parameters=False,
    637                                   error_score=self.error_score)
    638           for parameters, (train, test) in product(candidate_params,
--> 639                                                    cv.split(X, y, groups)))
        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=3, random_state=None, shuffle=False)>
        X = <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>
        y = array([False, False, False, ..., False, False, False], dtype=bool)
        groups = None
    640 
    641         # if one choose to see train score, "out" will contain train score info
    642         if self.return_train_score:
    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)
    784             if pre_dispatch == "all" or n_jobs == 1:
    785                 # The iterable was consumed all at once by the above for loop.
    786                 # No need to wait for async callbacks to trigger to
    787                 # consumption.
    788                 self._iterating = False
--> 789             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>
    790             # Make sure that we get a last message telling us we are done
    791             elapsed_time = time.time() - self._start_time
    792             self._print('Done %3i out of %3i | elapsed: %s finished',
    793                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
ValueError                                         Mon Mar 19 21:42:04 2018
PID: 31819                  Python 3.6.3: /home/wolfm2/anaconda3/bin/python
...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), <364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, array([False, False, False, ..., False, False, False], dtype=bool), {'score': <function _passthrough_scorer>}, memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), array([     0,      1,      2, ..., 121644, 121651, 121685]), 0, {'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01})
        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<364000x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), scorer={'score': <function _passthrough_scorer>}, train=memmap([121300, 121301, 121302, ..., 363997, 363998, 363999]), test=array([     0,      1,      2, ..., 121644, 121651, 121685]), verbose=0, parameters={'activation': 'logistic', 'alpha': array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06]), 'epsilon': 0.001, 'hidden_layer_sizes': (100, 1), 'learning_rate': 'constant', 'tol': 0.01}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')
    453 
    454     try:
    455         if y_train is None:
    456             estimator.fit(X_train, **fit_params)
    457         else:
--> 458             estimator.fit(X_train, y_train, **fit_params)
        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,
       verbose=False, warm_start=False)>
        X_train = <242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>
        y_train = array([False, False, False, ..., False, False, False], dtype=bool)
        fit_params = {}
    459 
    460     except Exception as e:
    461         # Note fit time as time until error
    462         fit_time = time.time() - start_time

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool))
    968         Returns
    969         -------
    970         self : returns a trained MLP model.
    971         """
    972         return self._fit(X, y, incremental=(self.warm_start and
--> 973                                             hasattr(self, "classes_")))
        self = MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False)
    974 
    975     @property
    976     def partial_fit(self):
    977         """Fit the model to data matrix X and target y.

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False), X=<242666x786435 sparse matrix of type '<class 'nu... stored elements in Compressed Sparse Row format>, y=array([False, False, False, ..., False, False, False], dtype=bool), incremental=False)
    321         if not hasattr(hidden_layer_sizes, "__iter__"):
    322             hidden_layer_sizes = [hidden_layer_sizes]
    323         hidden_layer_sizes = list(hidden_layer_sizes)
    324 
    325         # Validate input parameters.
--> 326         self._validate_hyperparameters()
        self._validate_hyperparameters = <bound method BaseMultilayerPerceptron._validate...ion=0.1,
       verbose=False, warm_start=False)>
    327         if np.any(np.array(hidden_layer_sizes) <= 0):
    328             raise ValueError("hidden_layer_sizes must be > 0, got %s." %
    329                              hidden_layer_sizes)
    330 

...........................................................................
/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py in _validate_hyperparameters(self=MLPClassifier(activation='logistic',
       alph...tion=0.1,
       verbose=False, warm_start=False))
    387         if not isinstance(self.shuffle, bool):
    388             raise ValueError("shuffle must be either True or False, got %s." %
    389                              self.shuffle)
    390         if self.max_iter <= 0:
    391             raise ValueError("max_iter must be > 0, got %s." % self.max_iter)
--> 392         if self.alpha < 0.0:
        self.alpha = array([  1.00000000e-01,   1.00000000e-02,   1.0...0000000e-04,   1.00000000e-05,   1.00000000e-06])
    393             raise ValueError("alpha must be >= 0, got %s." % self.alpha)
    394         if (self.learning_rate in ["constant", "invscaling", "adaptive"] and
    395                 self.learning_rate_init <= 0.0):
    396             raise ValueError("learning_rate_init must be > 0, got %s." %

ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
___________________________________________________________________________

.:
total 4
drwxrwxr-x 6 wolfm2 wolfm2 4096 Mar 19 20:54 minibook

./minibook:
total 16
drwxrwxr-x 3 wolfm2 wolfm2 4096 Mar 19 21:00 amazon
drwxrwxr-x 2 wolfm2 wolfm2 4096 Mar  7 11:47 amazonFirstIter
drwxrwxr-x 3 wolfm2 wolfm2 4096 Mar 14 22:15 amazonIter
drwxrwxr-x 2 wolfm2 wolfm2 4096 Mar  9 14:16 system

./minibook/amazon:
total 273672
-rw-rw-r-- 1 wolfm2 wolfm2      2978 Mar  9 13:31 _00_split.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2     31638 Mar  9 16:12 _01_train.0.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2     61503 Mar 19 20:54 _01_train.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2     26250 Mar  7 11:47 _02_test.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2     20981 Mar  7 11:47 _03_submission.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2 248373493 Mar  6 20:06 Amazon.csv
-rw-rw-r-- 1 wolfm2 wolfm2      2418 Mar 19 21:42 GridSearch.txt
-rw-rw-r-- 1 wolfm2 wolfm2       642 Mar 19 20:59 hv0.pkl
-rw-rw-r-- 1 wolfm2 wolfm2       648 Mar 19 20:59 hv1.pkl
-rw-rw-r-- 1 wolfm2 wolfm2     62316 Mar 19 21:42 job.log
-rw-rw-r-- 1 wolfm2 wolfm2      2632 Mar  7 11:47 my_measures.py
-rw-rw-r-- 1 wolfm2 wolfm2    144100 Mar 19 21:42 output.ipynb
drwxrwxr-x 2 wolfm2 wolfm2      4096 Mar 19 21:00 __pycache__
-rw-rw-r-- 1 wolfm2 wolfm2      3534 Mar  7 11:47 README.md
-rw-rw-r-- 1 wolfm2 wolfm2  18874951 Mar 19 21:00 sc.pkl
-rw-rw-r-- 1 wolfm2 wolfm2  12583580 Mar 19 21:00 transformer.pkl

./minibook/amazon/__pycache__:
total 4
-rw-rw-r-- 1 wolfm2 wolfm2 2043 Mar 19 21:00 my_measures.cpython-36.pyc

./minibook/amazonFirstIter:
total 61448
-rw-rw-r-- 1 wolfm2 wolfm2    20808 Mar  7 11:47 _03_submission.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2      557 Mar  7 11:47 hv.pkl
-rw-rw-r-- 1 wolfm2 wolfm2  2098273 Mar  7 11:47 lgs.pkl
-rw-rw-r-- 1 wolfm2 wolfm2     2632 Mar  7 11:47 my_measures.py
-rw-rw-r-- 1 wolfm2 wolfm2 50282018 Mar  7 11:47 raw_data_test.csv
-rw-rw-r-- 1 wolfm2 wolfm2  6292015 Mar  7 11:47 sc.pkl
-rw-rw-r-- 1 wolfm2 wolfm2  4194972 Mar  7 11:47 transformer.pkl
-rw-rw-r-- 1 wolfm2 wolfm2     8988 Mar  7 11:47 ver.py

./minibook/amazonIter:
total 49204
-rw-rw-r-- 1 wolfm2 wolfm2    22513 Mar 12 08:18 _03_submission.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2    24197 Mar 14 22:16 job.log
-rw-rw-r-- 1 wolfm2 wolfm2     2632 Mar 10 19:49 my_measures.py
-rw-rw-r-- 1 wolfm2 wolfm2    28710 Mar 14 22:16 output.ipynb
drwxrwxr-x 2 wolfm2 wolfm2     4096 Mar 14 22:15 __pycache__
-rw-rw-r-- 1 wolfm2 wolfm2 50282018 Mar 10 19:49 raw_data_test.csv
-rw-rw-r-- 1 wolfm2 wolfm2     8988 Mar 10 19:49 ver.py

./minibook/amazonIter/__pycache__:
total 4
-rw-rw-r-- 1 wolfm2 wolfm2 2047 Mar 14 22:15 my_measures.cpython-36.pyc

./minibook/system:
total 56
-rw-rw-r-- 1 wolfm2 wolfm2 22404 Mar  9 14:16 job.log
-rw-rw-r-- 1 wolfm2 wolfm2  1484 Mar  9 14:16 output.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2   993 Mar  9 14:12 runner.ipynb
-rw-rw-r-- 1 wolfm2 wolfm2 20853 Mar  9 14:16 tst.txt
USER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
root         1  0.0  0.0 185252  4176 ?        Ss   Mar18   0:01 /sbin/init splash
root         2  0.0  0.0      0     0 ?        S    Mar18   0:00 [kthreadd]
root         4  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/0:0H]
root         6  0.0  0.0      0     0 ?        S<   Mar18   0:00 [mm_percpu_wq]
root         7  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/0]
root         8  0.0  0.0      0     0 ?        S    Mar18   1:09 [rcu_sched]
root         9  0.0  0.0      0     0 ?        S    Mar18   0:00 [rcu_bh]
root        10  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/0]
root        11  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/0]
root        12  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/0]
root        13  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/1]
root        14  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/1]
root        15  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/1]
root        16  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/1]
root        18  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/1:0H]
root        19  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/2]
root        20  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/2]
root        21  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/2]
root        22  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/2]
root        24  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/2:0H]
root        25  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/3]
root        26  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/3]
root        27  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/3]
root        28  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/3]
root        30  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/3:0H]
root        31  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/4]
root        32  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/4]
root        33  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/4]
root        34  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/4]
root        36  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/4:0H]
root        37  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/5]
root        38  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/5]
root        39  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/5]
root        40  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/5]
root        42  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/5:0H]
root        43  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/6]
root        44  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/6]
root        45  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/6]
root        46  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/6]
root        48  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/6:0H]
root        49  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/7]
root        50  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/7]
root        51  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/7]
root        52  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/7]
root        54  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/7:0H]
root        55  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/8]
root        56  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/8]
root        57  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/8]
root        58  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/8]
root        60  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/8:0H]
root        61  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/9]
root        62  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/9]
root        63  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/9]
root        64  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/9]
root        66  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/9:0H]
root        67  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/10]
root        68  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/10]
root        69  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/10]
root        70  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/10]
root        72  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/10:0H]
root        73  0.0  0.0      0     0 ?        S    Mar18   0:00 [cpuhp/11]
root        74  0.0  0.0      0     0 ?        S    Mar18   0:00 [watchdog/11]
root        75  0.0  0.0      0     0 ?        S    Mar18   0:00 [migration/11]
root        76  0.0  0.0      0     0 ?        S    Mar18   0:00 [ksoftirqd/11]
root        78  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/11:0H]
root        79  0.0  0.0      0     0 ?        S    Mar18   0:00 [kdevtmpfs]
root        80  0.0  0.0      0     0 ?        S<   Mar18   0:00 [netns]
root        83  0.0  0.0      0     0 ?        S    Mar18   0:00 [khungtaskd]
root        84  0.0  0.0      0     0 ?        S    Mar18   0:00 [oom_reaper]
root        85  0.0  0.0      0     0 ?        S<   Mar18   0:00 [writeback]
root        86  0.0  0.0      0     0 ?        S    Mar18   0:00 [kcompactd0]
root        87  0.0  0.0      0     0 ?        SN   Mar18   0:00 [ksmd]
root        88  0.0  0.0      0     0 ?        SN   Mar18   0:00 [khugepaged]
root        89  0.0  0.0      0     0 ?        S<   Mar18   0:00 [crypto]
root        90  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kintegrityd]
root        91  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kblockd]
root       102  0.0  0.0      0     0 ?        S<   Mar18   0:00 [ata_sff]
root       103  0.0  0.0      0     0 ?        S<   Mar18   0:00 [md]
root       104  0.0  0.0      0     0 ?        S<   Mar18   0:00 [edac-poller]
root       105  0.0  0.0      0     0 ?        S<   Mar18   0:00 [devfreq_wq]
root       106  0.0  0.0      0     0 ?        S<   Mar18   0:00 [watchdogd]
root       109  0.0  0.0      0     0 ?        S    Mar18   0:00 [kauditd]
root       110  0.0  0.0      0     0 ?        S    Mar18   0:52 [kswapd0]
root       111  0.0  0.0      0     0 ?        S    Mar18   0:00 [ecryptfs-kthrea]
root       153  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kthrotld]
root       154  0.0  0.0      0     0 ?        S<   Mar18   0:00 [acpi_thermal_pm]
root       159  0.0  0.0      0     0 ?        S<   Mar18   0:00 [ipv6_addrconf]
root       184  0.0  0.0      0     0 ?        S<   Mar18   0:00 [charger_manager]
root       236  0.0  0.0      0     0 ?        S<   Mar18   0:00 [nvme-wq]
root       238  0.0  0.0      0     0 ?        S    Mar18   0:00 [kworker/11:2]
root       239  0.0  0.0      0     0 ?        S    Mar18   0:00 [nvidia-modeset]
root       240  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_0]
root       241  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_0]
root       242  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_1]
root       243  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_1]
root       244  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_2]
root       245  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_2]
root       246  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_3]
root       247  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_3]
root       248  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_4]
root       249  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_4]
root       250  0.0  0.0      0     0 ?        S    Mar18   0:00 [scsi_eh_5]
root       251  0.0  0.0      0     0 ?        S<   Mar18   0:00 [scsi_tmf_5]
root       259  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/0:1H]
root       285  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/10:1H]
root       289  0.0  0.0      0     0 ?        S    Mar18   0:01 [jbd2/nvme0n1p1-]
root       290  0.0  0.0      0     0 ?        S<   Mar18   0:00 [ext4-rsv-conver]
root       324  0.0  0.0  59972 26268 ?        Ss   Mar18   0:05 /lib/systemd/systemd-journald
root       325  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/2:1H]
root       341  0.0  0.0  46204  1736 ?        Ss   Mar18   0:00 /lib/systemd/systemd-udevd
root       342  0.0  0.0      0     0 ?        S<   Mar18   0:00 [cfg80211]
root       369  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/1:1H]
systemd+   465  0.0  0.0 102384   172 ?        Ssl  Mar18   0:00 /lib/systemd/systemd-timesyncd
root       564  0.0  0.0      0     0 ?        S    Mar18   0:00 [UVM global queu]
root       565  0.0  0.0      0     0 ?        S    Mar18   0:00 [UVM Tools Event]
root       583  1.6  0.0      0     0 ?        S    Mar18  35:07 [irq/151-nvidia]
root       584  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/u25:0]
root       586  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/u25:2]
root       593  0.0  0.0      0     0 ?        S    Mar18   0:00 [nvidia]
root       595  0.0  0.0      0     0 ?        S    Mar18   0:00 [irq/152-mei_me]
root       821  0.0  0.0      0     0 ?        S<   Mar18   0:00 [led_workqueue]
root       875  0.0  0.0  29008   868 ?        Ss   Mar18   0:00 /usr/sbin/cron -f
root       882  0.0  0.0   4396     0 ?        Ss   Mar18   0:00 /usr/sbin/acpid
avahi      887  0.0  0.0  45048   268 ?        Ss   Mar18   0:00 avahi-daemon: running [d12ml.local]
nvidia-+   888  0.0  0.0  17140     0 ?        Ss   Mar18   0:00 /usr/bin/nvidia-persistenced --user nvidia-persistenced --no-persistence-mode --verbose
root       895  0.0  0.0 413608   348 ?        Ssl  Mar18   0:00 /usr/sbin/ModemManager
root       897  0.0  0.0  31956     0 ?        Ss   Mar18   0:00 /usr/lib/bluetooth/bluetoothd
root       899  0.0  0.0  28628  1860 ?        Ss   Mar18   0:00 /lib/systemd/systemd-logind
root       901  0.0  0.0 166432   388 ?        Ssl  Mar18   0:10 /usr/sbin/thermald --no-daemon --dbus-enable
root       902  0.0  0.0 287200   996 ?        Ssl  Mar18   0:02 /usr/lib/accountsservice/accounts-daemon
root       907  0.0  0.0 767392  5144 ?        Ssl  Mar18   0:05 /usr/lib/snapd/snapd
syslog     914  0.0  0.0 256396   280 ?        Ssl  Mar18   0:01 /usr/sbin/rsyslogd -n
message+   916  0.0  0.0  44068  2576 ?        Ss   Mar18   0:00 /usr/bin/dbus-daemon --system --address=systemd: --nofork --nopidfile --systemd-activation
avahi      921  0.0  0.0  44784    24 ?        S    Mar18   0:00 avahi-daemon: chroot helper
root       939  0.0  0.0 451300  2372 ?        Ssl  Mar18   0:00 /usr/sbin/NetworkManager --no-daemon
root       965  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/4:1H]
root       967  0.0  0.0 289688  4240 ?        Ssl  Mar18   0:01 /usr/lib/policykit-1/polkitd --no-debug
root       969  0.0  0.0  19584   492 ?        Ss   Mar18   0:10 /usr/sbin/irqbalance --pid=/var/run/irqbalance.pid
root       986  0.0  0.0  65508  1168 ?        Ss   Mar18   0:00 /usr/sbin/sshd -D
root      1025  0.0  0.0 287712  2204 ?        Ssl  Mar18   0:00 /usr/sbin/lightdm
root      1033  0.0  0.0 226640 14084 tty7     Ssl+ Mar18   0:01 /usr/lib/xorg/Xorg -core :0 -seat seat0 -auth /var/run/lightdm/root/:0 -nolisten tcp vt7 -novtswitch
root      1068  0.0  0.0 226180  1648 ?        Sl   Mar18   0:00 lightdm --session-child 16 19
lightdm   1071  0.0  0.0  45276  2136 ?        Ss   Mar18   0:00 /lib/systemd/systemd --user
lightdm   1072  0.0  0.0  63244    40 ?        S    Mar18   0:00 (sd-pam)
root      1079  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/5:1H]
lightdm   1080  0.0  0.0   4504     0 ?        Ss   Mar18   0:00 /bin/sh /usr/lib/lightdm/lightdm-greeter-session /usr/sbin/unity-greeter
lightdm   1085  0.0  0.0  42988   300 ?        Ss   Mar18   0:00 /usr/bin/dbus-daemon --fork --print-pid 5 --print-address 7 --session
lightdm   1086  0.0  0.0 919236 13628 ?        Sl   Mar18   0:03 /usr/sbin/unity-greeter
lightdm   1088  0.0  0.0 346956     0 ?        Sl   Mar18   0:00 /usr/lib/at-spi2-core/at-spi-bus-launcher --launch-immediately
lightdm   1093  0.0  0.0  42764     0 ?        S    Mar18   0:00 /usr/bin/dbus-daemon --config-file=/etc/at-spi2/accessibility.conf --nofork --print-address 3
lightdm   1095  0.0  0.0 206864   724 ?        Sl   Mar18   0:00 /usr/lib/at-spi2-core/at-spi2-registryd --use-gnome-session
lightdm   1101  0.0  0.0 274416     4 ?        Sl   Mar18   0:00 /usr/lib/gvfs/gvfsd
lightdm   1106  0.0  0.0 352264     0 ?        Sl   Mar18   0:00 /usr/lib/gvfs/gvfsd-fuse /run/user/108/gvfs -f -o big_writes
lightdm   1115  0.0  0.0 178532  2092 ?        Sl   Mar18   0:00 /usr/lib/dconf/dconf-service
root      1119  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/6:1H]
root      1120  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/8:1H]
root      1121  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/3:1H]
root      1122  0.0  0.0  82708     8 ?        S    Mar18   0:00 lightdm --session-child 12 19
lightdm   1126  0.0  0.0  45956   376 ?        S    Mar18   0:00 upstart --user --startup-event indicator-services-start
lightdm   1128  0.0  0.0 659472  5464 ?        Sl   Mar18   0:00 nm-applet
lightdm   1130  0.0  0.0 618940  4884 ?        Sl   Mar18   0:00 /usr/lib/unity-settings-daemon/unity-settings-daemon
lightdm   1132  0.0  0.0 363364  2108 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-messages/indicator-messages-service
lightdm   1133  0.0  0.0 342332     0 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-bluetooth/indicator-bluetooth-service
lightdm   1134  0.0  0.0 426524     0 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-power/indicator-power-service
lightdm   1135  0.0  0.0 457892  2776 ?        Ssl  Mar18   0:01 /usr/lib/x86_64-linux-gnu/indicator-datetime/indicator-datetime-service
lightdm   1136  0.0  0.0 563912 10012 ?        Ssl  Mar18   0:01 /usr/lib/x86_64-linux-gnu/indicator-keyboard/indicator-keyboard-service --use-gtk
lightdm   1137  0.0  0.0 669160  4220 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-sound/indicator-sound-service
lightdm   1138  0.0  0.0 830756  2132 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-session/indicator-session-service
lightdm   1140  0.0  0.0 403148     0 ?        Ssl  Mar18   0:00 /usr/lib/x86_64-linux-gnu/indicator-application/indicator-application-service
root      1184  0.0  0.0  93276   120 ?        Ss   07:35   0:00 /usr/sbin/cupsd -l
root      1185  0.0  0.0 274816  1484 ?        Ssl  07:35   0:00 /usr/sbin/cups-browsed
lightdm   1187  0.0  0.0 490132   904 ?        S<l  Mar18   0:00 /usr/bin/pulseaudio --start --log-target=syslog
rtkit     1189  0.0  0.0 183544     0 ?        SNsl Mar18   0:01 /usr/lib/rtkit/rtkit-daemon
root      1201  0.0  0.0 347260   176 ?        Ssl  Mar18   0:00 /usr/lib/upower/upowerd
colord    1228  0.0  0.0 309136     4 ?        Ssl  Mar18   0:00 /usr/lib/colord/colord
root      1246  0.0  0.0      0     0 ?        S    07:35   0:01 [kworker/0:0]
root      1262  0.0  0.0  16124  1256 ?        S    Mar18   0:00 /sbin/dhclient -d -q -sf /usr/lib/NetworkManager/nm-dhcp-helper -pf /var/run/dhclient-enp0s31f6.pid -lf /var/lib/NetworkManager/dhclient-45d90ee1-f2f7-475d-94b8-7fa88540ba33-enp0s31f6.lease -cf /var/lib/NetworkManager/dhclient-enp0s31f6.conf enp0s31f6
root      1272  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/9:1H]
nobody    1273  0.0  0.0  52864    88 ?        S    Mar18   0:00 /usr/sbin/dnsmasq --no-resolv --keep-in-foreground --no-hosts --bind-interfaces --pid-file=/var/run/NetworkManager/dnsmasq.pid --listen-address=127.0.1.1 --cache-size=0 --conf-file=/dev/null --proxy-dnssec --enable-dbus=org.freedesktop.NetworkManager.dnsmasq --conf-dir=/etc/NetworkManager/dnsmasq.d
root      1302  0.0  0.0      0     0 ?        S    07:35   0:00 [kworker/3:1]
lightdm   1318  0.0  0.0 481996  2168 ?        Sl   Mar18   0:00 /usr/lib/x86_64-linux-gnu/notify-osd
root      1432  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/11:1H]
whoopsie  1459  0.0  0.0 374012   304 ?        Ssl  Mar18   0:00 /usr/bin/whoopsie -f
root      1464  0.0  0.0  15936     0 tty1     Ss+  Mar18   0:00 /sbin/agetty --noclear tty1 linux
root      1734  0.0  0.0      0     0 ?        S<   Mar18   0:00 [kworker/7:1H]
root      5249  0.0  0.0      0     0 ?        S    Mar18   0:01 [kworker/4:0]
root      5852  0.0  0.0      0     0 ?        S    15:30   0:00 [kworker/0:2]
root      5861  0.0  0.0      0     0 ?        S    15:30   0:00 [kworker/2:3]
root     10359  0.0  0.0      0     0 ?        S    Mar18   0:01 [kworker/9:2]
root     15606  0.0  0.0      0     0 ?        S    17:51   0:00 [kworker/8:1]
root     15610  0.0  0.0      0     0 ?        S    17:51   0:00 [kworker/7:2]
root     15611  0.0  0.0      0     0 ?        S    17:51   0:00 [kworker/10:1]
root     15616  0.0  0.0      0     0 ?        S    17:51   0:00 [kworker/1:0]
root     15617  0.0  0.0      0     0 ?        S    17:51   0:00 [kworker/4:1]
root     15739  0.0  0.0      0     0 ?        S    17:52   0:00 [kworker/5:1]
root     17108  0.1  0.0      0     0 ?        S    11:11   1:04 [kworker/6:1]
root     17474  0.0  0.0      0     0 ?        S    11:15   0:00 [kworker/2:1]
root     19167  0.3  0.0      0     0 ?        S    11:34   2:06 [kworker/6:0]
root     19698  0.0  0.0      0     0 ?        S    11:39   0:00 [kworker/7:0]
root     21530  0.0  0.0      0     0 ?        S    11:58   0:00 [kworker/11:3]
root     25828  0.0  0.0      0     0 ?        S    12:57   0:00 [kworker/3:0]
root     26541  0.0  0.0      0     0 ?        S    Mar18   0:01 [kworker/10:2]
root     26614  0.0  0.0      0     0 ?        S    13:08   0:00 [kworker/5:2]
root     27538  0.0  0.0      0     0 ?        S    06:10   0:00 [kworker/1:1]
root     28286  0.0  0.0  52312  2924 ?        S    20:54   0:00 /usr/sbin/CRON -f
wolfm2   28288  0.0  0.0   4504   708 ?        Ss   20:54   0:00 /bin/sh -c /home/wolfm2/job.sh
wolfm2   28290  0.0  0.0  12544  2984 ?        S    20:54   0:00 /bin/bash /home/wolfm2/job.sh
root     28964  0.0  0.0      0     0 ?        S    21:02   0:00 [kworker/u24:1]
root     31132  0.0  0.0      0     0 ?        S    13:48   0:00 [kworker/8:0]
root     31133  0.0  0.0      0     0 ?        S    13:48   0:00 [kworker/9:0]
root     31381  0.0  0.0      0     0 ?        S    21:35   0:00 [kworker/u24:0]
wolfm2   31905  0.0  0.0  37364  3284 ?        R    21:42   0:00 ps aux
Mon Mar 19 21:42:07 EDT 2018
The following paths are ignored by one of your .gitignore files:
minibook/amazonIter/__pycache__/my_measures.cpython-36.pyc
Use -f if you really want to add them.
The following paths are ignored by one of your .gitignore files:
minibook/amazon/__pycache__/my_measures.cpython-36.pyc
Use -f if you really want to add them.
