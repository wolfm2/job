{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.000491,
     "end_time": "2018-03-15T02:15:07.473236",
     "exception": false,
     "start_time": "2018-03-15T02:15:07.472745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission 1, ML Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.271013,
     "end_time": "2018-03-15T02:15:07.750145",
     "exception": false,
     "start_time": "2018-03-15T02:15:07.479132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-15T02:15:07.750252",
     "exception": false,
     "start_time": "2018-03-15T02:15:07.750246",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read raw test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.410639,
     "end_time": "2018-03-15T02:15:08.166751",
     "exception": false,
     "start_time": "2018-03-15T02:15:07.756112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('raw_data_test.csv')\n",
    "print(amazon.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.009909,
     "end_time": "2018-03-15T02:15:08.176753",
     "exception": false,
     "start_time": "2018-03-15T02:15:08.166844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      264540        182243  182244  B005OSC218   AJZXTZ3I9A84H   \n",
      "1      146085        548350  548351  B004VLVD50  A39RNG8DUXG7ZM   \n",
      "2      281714        539422  539423  B001BDDT8K  A2FRFAQCWZJT3Q   \n",
      "3      280559        119141  119142  B001U0ON5M  A1YREIUL7VDQ0B   \n",
      "4      236948        352256  352257  B000E63L8S  A3JKXNOLX2QRJ7   \n",
      "\n",
      "                         ProfileName  HelpfulnessNumerator  \\\n",
      "0                             Jeromy                     1   \n",
      "1                         W. Chapman                     4   \n",
      "2        B. Davis \"The Happy Hermit\"                     1   \n",
      "3   Jennifer U. Heston \"ex-academic\"                     0   \n",
      "4  darlene conright \"alaskan darlin\"                     2   \n",
      "\n",
      "   HelpfulnessDenominator  Score        Time                  Summary  \\\n",
      "0                       1      5  1316995200                 The Best   \n",
      "1                       4      5  1331596800  Makes great dog bones !   \n",
      "2                       1      5  1228608000            Got Diarrhea?   \n",
      "3                       0      1  1350864000               Too runny!   \n",
      "4                       2      5  1163203200                Great tea   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  I've impressed so many of my friends by bustin...        1.0    False  \n",
      "1  I have a hard time finding the best ingredient...        1.0     True  \n",
      "2  This is an edit so I was unable to change my s...        1.0    False  \n",
      "3  This product does not work well at all.  We bo...        NaN    False  \n",
      "4  I have a cup of peppermint tea most mornings a...        1.0    False  \n",
      "0.0723956043956\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-03-15T02:15:08.176793",
     "exception": false,
     "start_time": "2018-03-15T02:15:08.176787",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.007874,
     "end_time": "2018-03-15T02:15:08.191049",
     "exception": false,
     "start_time": "2018-03-15T02:15:08.183175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.196374,
     "end_time": "2018-03-15T02:15:08.387526",
     "exception": false,
     "start_time": "2018-03-15T02:15:08.191152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "# from sklearn.feature_extraction.text import HashingVectorizer\n",
    "# hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "\n",
    "hv0 = joblib.load('../amazon/hv0.pkl')\n",
    "#X_hv = hv.transform(amazon.Text)\n",
    "amazon['timeFilter'] = amazon['Time'].apply(lambda x: str(int(x)%(86400 * 7))) # converts to day of week\n",
    "X_hv0 = hv0.transform(amazon.timeFilter + \" \" + amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# and a second domain where we look at the summary\n",
    "amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "hv1 = joblib.load('../amazon/hv1.pkl')\n",
    "X_hv1 = hv1.transform(amazon.summaryFilter) \n",
    "\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hv = sp.hstack([X_hv0, X_hv1], format='csr')\n",
    "\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# transformer = TfidfTransformer()\n",
    "transformer = joblib.load('../amazon/transformer.pkl') \n",
    "X_tfidf = transformer.transform(X_hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "\n",
    "amazon['summaryLen'] = amazon['summaryFilter'].str.len()\n",
    "#import zlib\n",
    "#amazon['nameHash'] = zlib.crc32(str(amazon['UserId']).encode('utf8'))\n",
    "#amazon['nameHash'] = amazon['UserId'].apply(lambda x: zlib.crc32(str(x).encode('utf8'))) # bad. don't do it this way\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\", \"summaryLen\"]]\n",
    "\n",
    "# X_quant_features = amazon[[\"Score\", \"reviewLen\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc = StandardScaler(with_mean=False)\n",
    "sc = joblib.load('../amazon/sc.pkl')\n",
    "X = sc.transform(X_matrix)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### predict `y` with the fit on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL: best from search\n",
    "from sklearn import linear_model\n",
    "\n",
    "lgs = joblib.load('../amazon/best.pkl') # pickle\n",
    "\n",
    "lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'best')\n",
    "lgs_performance.compute_measures()\n",
    "print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fits = [lgs_performance]\n",
    "\n",
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "environment_variables": {},
   "output_path": "output.ipynb",
   "parameters": null,
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}