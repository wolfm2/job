{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.000548,
     "end_time": "2018-04-01T00:44:13.377225",
     "exception": false,
     "start_time": "2018-04-01T00:44:13.376677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.267256,
     "end_time": "2018-04-01T00:44:13.652997",
     "exception": false,
     "start_time": "2018-04-01T00:44:13.385741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "%matplotlib inline   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.015874,
     "end_time": "2018-04-01T00:44:13.668960",
     "exception": false,
     "start_time": "2018-04-01T00:44:13.653086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.system('ps aux | grep wolfm2')\n",
    "#os.system('killall -s SIGKILL -u wolfm2')\n",
    "#os.system('cp /home/wolfm2/job.sh .; echo test 1>&2') #; cp ../job.log ../jerbb.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 5e-06,
     "end_time": "2018-04-01T00:44:13.669006",
     "exception": false,
     "start_time": "2018-04-01T00:44:13.669001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Read raw training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 1.5622,
     "end_time": "2018-04-01T00:44:15.240147",
     "exception": false,
     "start_time": "2018-04-01T00:44:13.677947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 14)\n"
     ]
    }
   ],
   "source": [
    "amazon = pd.read_csv('/home/wolfm2/amazon_data/raw_data_train.csv')\n",
    "print(amazon.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.012054,
     "end_time": "2018-04-01T00:44:15.252296",
     "exception": false,
     "start_time": "2018-04-01T00:44:15.240242",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  Unnamed: 0.1      Id   ProductId          UserId  \\\n",
      "0      150581        487850  487851  B0025UCD76  A28B2M0XRXHXIG   \n",
      "1      334018         21518   21519  B002QWP89S   A7JJX3KMDZD2F   \n",
      "2       76657        319457  319458  B001GVIUX6  A2S8RJ6DRKGYON   \n",
      "3      357903        248851  248852  B0009JRH1C  A1FLQ698D9C0C8   \n",
      "4      301824        394613  394614  B001B4VOQI  A2KJO9EPX17ZXE   \n",
      "\n",
      "                   ProfileName  HelpfulnessNumerator  HelpfulnessDenominator  \\\n",
      "0                         B622                     0                       0   \n",
      "1  Shinichi Isozaki \"shincyan\"                     1                       2   \n",
      "2                   M. Ronning                     1                       2   \n",
      "3                     G. Zhang                     4                       8   \n",
      "4                    Musical E                     0                       0   \n",
      "\n",
      "   Score        Time                                            Summary  \\\n",
      "0      5  1313020800                                         DELICIOUS!   \n",
      "1      5  1268524800                     The pet dog is delighted, too!   \n",
      "2      2  1313798400  may be healthy but my \"eat anything\" cat won't...   \n",
      "3      5  1255478400                  Weight Loss Benefits of Green Tea   \n",
      "4      5  1305849600                     Healthy High Quality Dog Treat   \n",
      "\n",
      "                                                Text  helpScore  helpful  \n",
      "0  This BBQ sauce is DELICIOUS!!  Sweet and tangy...        NaN    False  \n",
      "1  I gave a pet dog plural resemblance products, ...        0.5    False  \n",
      "2  I tried this in place of Iams.  My hefty maine...        0.5    False  \n",
      "3  Weight Loss Benefits of Green Tea<br />=======...        0.5    False  \n",
      "4  Yes, they are a bit expensive but, they are hi...        NaN    False  \n",
      "0.073206043956\n"
     ]
    }
   ],
   "source": [
    "print(amazon.head())\n",
    "print(amazon['helpful'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 6e-06,
     "end_time": "2018-04-01T00:44:15.252479",
     "exception": false,
     "start_time": "2018-04-01T00:44:15.252473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.009338,
     "end_time": "2018-04-01T00:44:15.271722",
     "exception": false,
     "start_time": "2018-04-01T00:44:15.262384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vectorizer = CountVectorizer()\n",
    "# corpus = amazon.Text.as_matrix()\n",
    "# X_bag_of_words = vectorizer.fit_transform(corpus)\n",
    "# print(X_bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.195183,
     "end_time": "2018-04-01T00:44:15.468528",
     "exception": false,
     "start_time": "2018-04-01T00:44:15.273345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('popular')\n",
    "\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 326.749922,
     "end_time": "2018-04-01T00:49:42.218541",
     "exception": false,
     "start_time": "2018-04-01T00:44:15.468619",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 786432)\n"
     ]
    }
   ],
   "source": [
    "# vectorize Bag of Words from review text; as sparse matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "#hv = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "#  analyzer=stemmed_words,\n",
    "\n",
    "# look at the text \n",
    "hv0 = HashingVectorizer(n_features=2 ** 19, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,3)) #, token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b')\n",
    "X_hv0 = hv0.fit_transform(amazon.Text) # mw adds uid as token\n",
    "\n",
    "# and a second domain where we look at the summary\n",
    "amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "hv1 = HashingVectorizer(n_features=2 ** 18, non_negative=True, strip_accents=ascii, tokenizer=LemmaTokenizer(), stop_words={'english'}, \n",
    "                           ngram_range=(1,3), token_pattern = r'\\b[a-zA-Z0-9]{3,}\\b')\n",
    "X_hv1 = hv1.fit_transform(amazon.summaryFilter) \n",
    "\n",
    "# Another hash domain we want to count but not scale\n",
    "amazon['ScoreX'] = amazon['Score'].apply(lambda x: str(x))  # converts to day of week\n",
    "amazon['timeFilter'] = amazon['Time'].apply(lambda x: str(int(x)%(86400 * 7))) # converts to day of week\n",
    "hv2 = HashingVectorizer(n_features=2 ** 17, non_negative=True, strip_accents=ascii, \n",
    "                           ngram_range=(1,1)) \n",
    "X_hv2 = hv2.fit_transform(amazon.timeFilter + \" \" + amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.ScoreX) # mw adds uid as token\n",
    "\n",
    "\n",
    "# hv0 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv0 = hv0.fit_transform(amazon.ProductId + \" \" + amazon.UserId + \" \" + amazon.Text) # mw adds uid as token\n",
    "\n",
    "# amazon['summaryFilter'] = amazon['Summary'].apply(lambda x: \" \" if x is np.nan else x) # some were np.nans\n",
    "\n",
    "# hv1 = HashingVectorizer(n_features=2 ** 17, non_negative=True)\n",
    "# X_hv1 = hv1.fit_transform(amazon.summaryFilter)\n",
    "\n",
    "import scipy.sparse as sp\n",
    "X_hv = sp.hstack([X_hv0, X_hv1], format='csr')\n",
    "\n",
    "print(X_hv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.009182,
     "end_time": "2018-04-01T00:49:42.227820",
     "exception": false,
     "start_time": "2018-04-01T00:49:42.218638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x = amazon.UserId + \" \" +  amazon.Text\n",
    "# x.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.012725,
     "end_time": "2018-04-01T00:49:42.243126",
     "exception": false,
     "start_time": "2018-04-01T00:49:42.230401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hv2.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to be able to use this model fit on other data (the test set)\n",
    "# So let's save a copy of this instance of HashingVectorizer to be able to transform other data with this fit\n",
    "# http://scikit-learn.org/stable/modules/model_persistence.html\n",
    "joblib.dump(hv0, 'hv0.pkl') # pickle\n",
    "joblib.dump(hv1, 'hv1.pkl') # pickle\n",
    "joblib.dump(hv2, 'hv2.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 12.286879,
     "end_time": "2018-04-01T00:49:54.530122",
     "exception": false,
     "start_time": "2018-04-01T00:49:42.243243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transformer.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "X_tfidf = transformer.fit_transform(X_hv)\n",
    "\n",
    "joblib.dump(transformer, 'transformer.pkl') # pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.009893,
     "end_time": "2018-04-01T00:49:54.540105",
     "exception": false,
     "start_time": "2018-04-01T00:49:54.530212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-04-01T00:49:54.542805",
     "exception": false,
     "start_time": "2018-04-01T00:49:54.542798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create additional quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.385106,
     "end_time": "2018-04-01T00:49:54.938084",
     "exception": false,
     "start_time": "2018-04-01T00:49:54.552978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Score  reviewLen  summaryLen  rlMeanDist  slMeanDist\n",
      "0      5        110          10          30           2\n",
      "1      5        140          30          60          22\n",
      "2      2        471          55         391          47\n",
      "3      5      10800          33       10720          25\n",
      "4      5        152          30          72          22\n",
      "5      4        231          60         151          52\n",
      "6      5        271          22         191          14\n",
      "7      5        320          19         240          11\n",
      "8      2        362          58         282          50\n",
      "9      5        283          16         203           8\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# features from Amazon.csv to add to feature set\n",
    "amazon['reviewLen'] = amazon['Text'].str.len()\n",
    "amazon['summaryLen'] = amazon['summaryFilter'].str.len()\n",
    "\n",
    "amazon['rlMeanDist'] = amazon['reviewLen'].apply(lambda x: abs(x-80)) # 80 is avg summary len. Thx George!\n",
    "amazon['slMeanDist'] = amazon['summaryLen'].apply(lambda x: abs(x-8)) # 8. just guessing here.\n",
    "\n",
    "#import zlib\n",
    "#amazon['nameHash'] = zlib.crc32(str(amazon['UserId']).encode('utf8'))\n",
    "#amazon['nameHash'] = amazon['UserId'].apply(lambda x: zlib.crc32(str(x).encode('utf8'))) # bad. don't do it this way\n",
    "\n",
    "X_quant_features = amazon[[\"Score\", \"reviewLen\", \"summaryLen\", \"rlMeanDist\", \"slMeanDist\"]]\n",
    "print(X_quant_features.head(10))\n",
    "print(type(X_quant_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-04-01T00:49:54.938183",
     "exception": false,
     "start_time": "2018-04-01T00:49:54.938176",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Combine all quantitative features into a single sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 21.206018,
     "end_time": "2018-04-01T00:50:16.154400",
     "exception": false,
     "start_time": "2018-04-01T00:49:54.948382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 917509)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "X_combined = hstack([X_tfidf, X_quant_features_csr, X_hv2])  # we dont want to penalize hv2 w tfidf MW\n",
    "X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "print(X_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-04-01T00:50:16.154504",
     "exception": false,
     "start_time": "2018-04-01T00:50:16.154497",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create `X`, scaled matrix of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 2.818442,
     "end_time": "2018-04-01T00:50:18.983530",
     "exception": false,
     "start_time": "2018-04-01T00:50:16.165088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364000, 917509)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['sc.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler(with_mean=False)\n",
    "X = sc.fit_transform(X_matrix)\n",
    "print(X.shape)\n",
    "\n",
    "joblib.dump(sc, 'sc.pkl') # pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 7e-06,
     "end_time": "2018-04-01T00:50:18.983629",
     "exception": false,
     "start_time": "2018-04-01T00:50:18.983622",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### create `y`, vector of Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.013017,
     "end_time": "2018-04-01T00:50:19.007462",
     "exception": false,
     "start_time": "2018-04-01T00:50:18.994445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y = amazon['helpful'].values\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 8e-06,
     "end_time": "2018-04-01T00:50:19.007638",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.007630",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### fit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.012646,
     "end_time": "2018-04-01T00:50:19.031398",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.018752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from my_measures import BinaryClassificationPerformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 0.015444,
     "end_time": "2018-04-01T00:50:19.046876",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.031432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: SVM, linear\n",
    "# from sklearn import linear_model\n",
    "# svm = linear_model.SGDClassifier()\n",
    "# svm.fit(X, y)\n",
    "# joblib.dump(svm, 'svm.pkl') # pickle\n",
    "\n",
    "# svm_performance = BinaryClassificationPerformance(svm.predict(X), y, 'svm')\n",
    "# svm_performance.compute_measures()\n",
    "# print(svm_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "papermill": {
     "duration": 0.012676,
     "end_time": "2018-04-01T00:50:19.059583",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.046907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: logistic regression\n",
    "# from sklearn import linear_model\n",
    "# #lgs = linear_model.SGDClassifier(loss='log', n_iter=50, alpha=0.00001)\n",
    "# lgs = linear_model.SGDClassifier(loss='log', n_iter=1000, alpha=0.1)\n",
    "\n",
    "# lgs.fit(X, y)\n",
    "# joblib.dump(lgs, 'lgs.pkl') # pickle\n",
    "\n",
    "# lgs_performance = BinaryClassificationPerformance(lgs.predict(X), y, 'lgs')\n",
    "# lgs_performance.compute_measures()\n",
    "# print(lgs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "papermill": {
     "duration": 0.009416,
     "end_time": "2018-04-01T00:50:19.069030",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.059614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Naive Bayes\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# nbs = MultinomialNB()\n",
    "# nbs.fit(X, y)\n",
    "# joblib.dump(nbs, 'nbs.pkl') # pickle\n",
    "\n",
    "# nbs_performance = BinaryClassificationPerformance(nbs.predict(X), y, 'nbs')\n",
    "# nbs_performance.compute_measures()\n",
    "# print(nbs_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "papermill": {
     "duration": 0.009561,
     "end_time": "2018-04-01T00:50:19.081899",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.072338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Ridge Regression Classifier\n",
    "# from sklearn import linear_model\n",
    "# rdg = linear_model.RidgeClassifier()\n",
    "# rdg.fit(X, y)\n",
    "# joblib.dump(rdg, 'rdg.pkl') # pickle\n",
    "\n",
    "# rdg_performance = BinaryClassificationPerformance(rdg.predict(X), y, 'rdg')\n",
    "# rdg_performance.compute_measures()\n",
    "# print(rdg_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "papermill": {
     "duration": 0.009463,
     "end_time": "2018-04-01T00:50:19.094699",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.085236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # MODEL: Perceptron\n",
    "# from sklearn import linear_model\n",
    "# prc = linear_model.SGDClassifier(loss='perceptron')\n",
    "# prc.fit(X, y)\n",
    "# joblib.dump(prc, 'prc.pkl') # pickle\n",
    "\n",
    "# prc_performance = BinaryClassificationPerformance(prc.predict(X), y, 'prc')\n",
    "# prc_performance.compute_measures()\n",
    "# print(prc_performance.performance_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 23291.509921,
     "end_time": "2018-04-01T07:18:30.607792",
     "exception": false,
     "start_time": "2018-04-01T00:50:19.097871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=1000,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 253.65326587,  248.46028272,  246.53344075,  249.2380077 ,\n",
      "        247.19768532,  245.22792649]), 'std_fit_time': array([ 2.20890299,  2.2908685 ,  2.20248491,  2.81734194,  2.8313972 ,\n",
      "        4.84952771]), 'mean_score_time': array([ 0.09881965,  0.09807253,  0.09467149,  0.09535694,  0.09441694,\n",
      "        0.08860072]), 'std_score_time': array([ 0.00063378,  0.00272002,  0.00157707,  0.00205663,  0.00175158,\n",
      "        0.00891786]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.94309921,  0.94274482,  0.9430168 ,  0.94198658,  0.94218438,\n",
      "        0.94021461]), 'split1_test_score': array([ 0.94302457,  0.94242292,  0.94253006,  0.94225808,  0.94196962,\n",
      "        0.94072511]), 'split2_test_score': array([ 0.94301633,  0.94256303,  0.94285149,  0.94220863,  0.9423405 ,\n",
      "        0.94090643]), 'mean_test_score': array([ 0.9430467 ,  0.94257692,  0.94279945,  0.9421511 ,  0.94216484,\n",
      "        0.94061538]), 'std_test_score': array([  3.72827822e-05,   1.31782489e-04,   2.02087320e-04,\n",
      "         1.18069880e-04,   1.52040638e-04,   2.92896822e-04]), 'rank_test_score': array([1, 3, 2, 5, 4, 6], dtype=int32), 'split0_train_score': array([ 0.99946016,  0.99983104,  0.99990934,  0.9999011 ,  0.99990934,\n",
      "        0.99990522]), 'split1_train_score': array([ 0.99939835,  0.99984753,  0.99992582,  0.99992995,  0.99990934,\n",
      "        0.99993407]), 'split2_train_score': array([ 0.99939011,  0.99979396,  0.99986401,  0.99988462,  0.99987225,\n",
      "        0.99987637]), 'mean_train_score': array([ 0.99941621,  0.99982418,  0.99989973,  0.99990522,  0.99989698,\n",
      "        0.99990522]), 'std_train_score': array([  3.12621196e-05,   2.24030663e-05,   2.61349424e-05,\n",
      "         1.87337702e-05,   1.74832974e-05,   2.35527536e-05])}\n",
      "0.943046703297\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26145, 'TN': 337327, 'FP': 26, 'FN': 502, 'Accuracy': 0.99854945054945055, 'Precision': 0.99900653394979178, 'Recall': 0.98116110631590803, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=None, n_iter=1000,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 400.37177467,  315.36566369,  313.78205331,  315.07000589,\n",
      "        308.94108431,  314.54294109]), 'std_fit_time': array([ 60.78483871,   2.63124921,   2.85919545,   3.11369655,\n",
      "         2.80316614,   6.17637067]), 'mean_score_time': array([ 0.09141874,  0.10649689,  0.09698606,  0.10724648,  0.09728996,\n",
      "        0.09597651]), 'std_score_time': array([ 0.00644764,  0.01383484,  0.0141019 ,  0.01433942,  0.01431886,\n",
      "        0.01683925]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.9372476 ,  0.9456459 ,  0.94519261,  0.94509371,  0.94422009,\n",
      "        0.94342888]), 'split1_test_score': array([ 0.93753554,  0.9458515 ,  0.94538996,  0.94510974,  0.94398886,\n",
      "        0.94355204]), 'split2_test_score': array([ 0.93724708,  0.94548886,  0.94506853,  0.94485424,  0.94394765,\n",
      "        0.94323886]), 'mean_test_score': array([ 0.93734341,  0.94566209,  0.94521703,  0.94501923,  0.9440522 ,\n",
      "        0.94340659]), 'std_test_score': array([ 0.00013586,  0.00014849,  0.00013235,  0.00011685,  0.0001199 ,\n",
      "        0.00012883]), 'rank_test_score': array([6, 1, 2, 3, 4, 5], dtype=int32), 'split0_train_score': array([ 0.95980483,  0.99977335,  0.99990934,  0.99990522,  0.99988049,\n",
      "        0.99987637]), 'split1_train_score': array([ 0.96025418,  0.99977335,  0.9999217 ,  0.99992995,  0.99993407,\n",
      "        0.99993407]), 'split2_train_score': array([ 0.95980088,  0.9997239 ,  0.99985165,  0.99987225,  0.99982692,\n",
      "        0.99985577]), 'mean_train_score': array([ 0.9599533 ,  0.99975687,  0.99989423,  0.99990247,  0.99988049,\n",
      "        0.99988874]), 'std_train_score': array([  2.12759691e-04,   2.33109604e-05,   3.05302684e-05,\n",
      "         2.36327141e-05,   4.37408282e-05,   3.31383093e-05])}\n",
      "0.945662087912\n",
      "0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26501, 'TN': 337338, 'FP': 15, 'FN': 146, 'Accuracy': 0.99955769230769231, 'Precision': 0.99943430381656362, 'Recall': 0.99452095920741546, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='perceptron', max_iter=None,\n",
      "       n_iter=1000, n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 257.63656704,  263.1200974 ,  257.79031022,  263.0709579 ,\n",
      "        257.67523003,  246.85159564]), 'std_fit_time': array([  7.50479171,   7.48082975,   7.53402491,   7.483968  ,\n",
      "         7.439451  ,  20.23621968]), 'mean_score_time': array([ 0.1102891 ,  0.10976879,  0.10638547,  0.1102465 ,  0.10669478,\n",
      "        0.09893044]), 'std_score_time': array([ 0.00464499,  0.00468094,  0.00453136,  0.00448409,  0.00464856,\n",
      "        0.01403702]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.93981077,  0.942819  ,  0.94383273,  0.94342888,  0.9425635 ,\n",
      "        0.94037945]), 'split1_test_score': array([ 0.9402883 ,  0.94299984,  0.94406303,  0.94367567,  0.942596  ,\n",
      "        0.94093116]), 'split2_test_score': array([ 0.94065094,  0.94328006,  0.94380754,  0.94338721,  0.94262896,\n",
      "        0.94066742]), 'mean_test_score': array([ 0.94025   ,  0.94303297,  0.9439011 ,  0.94349725,  0.94259615,\n",
      "        0.94065934]), 'std_test_score': array([  3.44063767e-04,   1.89682157e-04,   1.14965371e-04,\n",
      "         1.27301463e-04,   2.67245385e-05,   2.25306409e-04]), 'rank_test_score': array([6, 3, 1, 2, 4, 5], dtype=int32), 'split0_train_score': array([ 0.99985989,  0.99988462,  0.99989286,  0.99985577,  0.99983104,\n",
      "        0.99982692]), 'split1_train_score': array([ 0.9999011 ,  0.99987637,  0.99990934,  0.99990934,  0.99989698,\n",
      "        0.9999217 ]), 'split2_train_score': array([ 0.9998228 ,  0.99983929,  0.99983104,  0.99984753,  0.99983929,\n",
      "        0.99983104]), 'mean_train_score': array([ 0.99986126,  0.99986676,  0.99987775,  0.99987088,  0.99985577,\n",
      "        0.99985989]), 'std_train_score': array([  3.19792136e-05,   1.97150767e-05,   3.37027563e-05,\n",
      "         2.74038317e-05,   2.93327879e-05,   4.37410074e-05])}\n",
      "0.943901098901\n",
      "0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wolfm2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26612, 'TN': 337341, 'FP': 12, 'FN': 35, 'Accuracy': 0.99987087912087913, 'Precision': 0.99954927884615385, 'Recall': 0.99868653131684615, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 2.75111834,  2.8077871 ,  2.84091798,  2.81855639,  2.83211573,\n",
      "        2.75467094]), 'std_fit_time': array([ 0.09280659,  0.02913759,  0.03125605,  0.02362764,  0.02303887,\n",
      "        0.07694091]), 'mean_score_time': array([ 0.29228354,  0.29801798,  0.29336373,  0.29971504,  0.29579043,\n",
      "        0.25958284]), 'std_score_time': array([ 0.0091776 ,  0.00878382,  0.00824752,  0.00693209,  0.00597715,\n",
      "        0.05330577]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.92537953,  0.93193993,  0.93440421,  0.93545915,  0.93608552,\n",
      "        0.93633277]), 'split1_test_score': array([ 0.9251399 ,  0.93125531,  0.93373608,  0.9350218 ,  0.93550806,\n",
      "        0.9359284 ]), 'split2_test_score': array([ 0.92532947,  0.93165091,  0.93418938,  0.93507125,  0.93559048,\n",
      "        0.93597785]), 'mean_test_score': array([ 0.92528297,  0.93161538,  0.93410989,  0.93518407,  0.93572802,\n",
      "        0.93607967]), 'std_test_score': array([ 0.0001032 ,  0.00028063,  0.00027849,  0.00019556,  0.00025502,\n",
      "        0.0001801 ]), 'rank_test_score': array([6, 5, 4, 3, 2, 1], dtype=int32), 'split0_train_score': array([ 0.99717719,  0.99760164,  0.99782829,  0.99790659,  0.9979478 ,\n",
      "        0.99799313]), 'split1_train_score': array([ 0.99714423,  0.99765934,  0.99787363,  0.99800962,  0.99807143,\n",
      "        0.99811676]), 'split2_train_score': array([ 0.99699588,  0.99747803,  0.99772116,  0.99781182,  0.99789423,\n",
      "        0.99793956]), 'mean_train_score': array([ 0.99710577,  0.99757967,  0.99780769,  0.99790934,  0.99797115,\n",
      "        0.99801648]), 'std_train_score': array([  7.88573693e-05,   7.56357516e-05,   6.39279414e-05,\n",
      "         8.07757585e-05,   7.42020427e-05,   7.42020231e-05])}\n",
      "0.93607967033\n",
      "1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26533, 'TN': 335760, 'FP': 1593, 'FN': 114, 'Accuracy': 0.99531043956043952, 'Precision': 0.94336201379506501, 'Recall': 0.99572184486058468, 'desc': 'best'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
      "        tol=0.001),\n",
      "       fit_params=None, iid=True, n_jobs=2,\n",
      "       param_grid={'alpha': array([  1.00000e+00,   1.00000e-01,   1.00000e-02,   1.00000e-03,\n",
      "         1.00000e-04,   1.00000e-05])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n",
      "{'mean_fit_time': array([ 1213.43395122,  1217.56024226,  1209.63371483,  1219.07967019,\n",
      "        1210.55260857,  1189.5403959 ]), 'std_fit_time': array([ 293.91155975,  282.74740876,  294.30426005,  277.42104317,\n",
      "        295.89726897,  264.85224545]), 'mean_score_time': array([ 0.09655039,  0.09548306,  0.09656882,  0.0948476 ,  0.09634296,\n",
      "        0.0882256 ]), 'std_score_time': array([ 0.00189604,  0.00178378,  0.00209841,  0.00206703,  0.00203089,\n",
      "        0.01105457]), 'param_alpha': masked_array(data = [1.0 0.10000000000000001 0.01 0.001 0.0001 1.0000000000000001e-05],\n",
      "             mask = [False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'alpha': 1.0}, {'alpha': 0.10000000000000001}, {'alpha': 0.01}, {'alpha': 0.001}, {'alpha': 0.0001}, {'alpha': 1.0000000000000001e-05}], 'split0_test_score': array([ 0.94259647,  0.94261295,  0.94261295,  0.94260471,  0.94261295,\n",
      "        0.94261295]), 'split1_test_score': array([ 0.94220039,  0.94220039,  0.94220039,  0.94220039,  0.94220039,\n",
      "        0.94220039]), 'split2_test_score': array([ 0.9421427 ,  0.94215094,  0.9421427 ,  0.9421427 ,  0.9421427 ,\n",
      "        0.9421427 ]), 'mean_test_score': array([ 0.94231319,  0.94232143,  0.94231868,  0.94231593,  0.94231868,\n",
      "        0.94231868]), 'std_test_score': array([ 0.00020169,  0.00020713,  0.00020941,  0.00020555,  0.00020941,\n",
      "        0.00020941]), 'rank_test_score': array([6, 1, 2, 5, 2, 2], dtype=int32), 'split0_train_score': array([ 0.99989286,  0.99989286,  0.99989286,  0.99989286,  0.99989286,\n",
      "        0.99989286]), 'split1_train_score': array([ 0.99990934,  0.99990934,  0.99990934,  0.99990934,  0.99990934,\n",
      "        0.99990934]), 'split2_train_score': array([ 0.99985989,  0.99985989,  0.99985989,  0.99985989,  0.99985989,\n",
      "        0.99985989]), 'mean_train_score': array([ 0.99988736,  0.99988736,  0.99988736,  0.99988736,  0.99988736,\n",
      "        0.99988736]), 'std_train_score': array([  2.05584895e-05,   2.05584895e-05,   2.05584895e-05,\n",
      "         2.05584895e-05,   2.05584895e-05,   2.05584895e-05])}\n",
      "0.942321428571\n",
      "0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 26647, 'Neg': 337353, 'TP': 26616, 'TN': 337339, 'FP': 14, 'FN': 31, 'Accuracy': 0.9998763736263736, 'Precision': 0.99947427713105519, 'Recall': 0.99883664202349232, 'desc': 'best'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier # mw\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "# alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "alphas = np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001])\n",
    "Cs = np.array([0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "# model = linear_model.SGDClassifier(loss='perceptron', max_iter=50) # max_iter 1000\n",
    "\n",
    "mlp = MLPClassifier(random_state=0)\n",
    "svm = linear_model.SGDClassifier(n_iter=1000)\n",
    "lgs = linear_model.SGDClassifier(loss='log', n_iter=1000)\n",
    "nbs = MultinomialNB()\n",
    "rdg = linear_model.RidgeClassifier()\n",
    "prc = linear_model.SGDClassifier(loss='perceptron', n_iter=1000)\n",
    "\n",
    "for model in [[svm,\"svm\"], [lgs,\"lgs\"], [prc,\"prc\"], [nbs,\"nbs\"], [rdg,\"rdg\"]]: \n",
    "# for model in []: \n",
    "# for model in [rdg]:    \n",
    "  fh = open(\"GridSearch.txt\", \"a\")\n",
    "  grid = GridSearchCV(estimator=model[0], param_grid=dict(alpha=alphas), n_jobs=2) #\n",
    "  grid.fit(X, y)\n",
    "  print(grid)\n",
    "  # summarize the results of the grid search\n",
    "  print(grid.cv_results_)\n",
    "  print(grid.best_score_)\n",
    "  print(grid.best_estimator_.alpha)\n",
    "\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(datetime.datetime.now()))\n",
    "  fh.write('\\n########\\n')\n",
    "  fh.write(str(model[0]) + '\\n')  \n",
    "  fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "  fh.write(str(grid.best_score_) + '\\n')  \n",
    "  fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "  fh.close()\n",
    "\n",
    "  # MODEL: BEST\n",
    "  best = grid.best_estimator_\n",
    "\n",
    "  best.fit(X, y)\n",
    "  joblib.dump(best, 'best.{}.pkl'.format(model[1])) # pickle\n",
    "\n",
    "  best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "  best_performance.compute_measures()\n",
    "  print(best_performance.performance_measures)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.011542,
     "end_time": "2018-04-01T07:18:30.619430",
     "exception": false,
     "start_time": "2018-04-01T07:18:30.607888",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npg = {\\'learning_rate\\': [\"constant\", \"invscaling\", \"adaptive\"],\\n\\'hidden_layer_sizes\\': [(100,1), (100,2), (100,3)],\\n#\\'alpha\\': [10.0 ** -np.arange(1, 7)],\\n\\'alpha\\': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\\n\\'activation\\': [\"logistic\", \"relu\", \"Tanh\"],\\n\\'tol\\': [1e-2, 1e-4, 1e-6],\\n\\'epsilon\\': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\\n}\\n\\nfh = open(\"GridSearch.txt\", \"a\")\\ngrid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\\ngrid.fit(X, y)\\nprint(grid)\\n# summarize the results of the grid search\\nprint(grid.cv_results_)\\nprint(grid.best_score_)\\nprint(grid.best_estimator_.alpha)\\n\\nfh.write(\\'\\n########\\n\\')\\nfh.write(str(datetime.datetime.now()))\\nfh.write(\\'\\n########\\n\\')\\nfh.write(str(model) + \\'\\n\\')  \\nfh.write(str(grid.cv_results_).replace(\", \\'\", \",\\n\\'\") + \\'\\n\\')\\nfh.write(str(grid.best_score_) + \\'\\n\\')  \\nfh.write(str(grid.best_estimator_.alpha) + \\'\\n\\')\\nfh.close()\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "pg = {'learning_rate': [\"constant\", \"invscaling\", \"adaptive\"],\n",
    "'hidden_layer_sizes': [(100,1), (100,2), (100,3)],\n",
    "#'alpha': [10.0 ** -np.arange(1, 7)],\n",
    "'alpha': [1, 0.1, 0.01, 0.001, 0.0001, 0.00001],\n",
    "'activation': [\"logistic\", \"relu\", \"Tanh\"],\n",
    "'tol': [1e-2, 1e-4, 1e-6],\n",
    "'epsilon': [1e-3, 1e-7, 1e-8, 1e-9, 1e-8]\n",
    "}\n",
    "\n",
    "fh = open(\"GridSearch.txt\", \"a\")\n",
    "grid = GridSearchCV(estimator=mlp, param_grid=pg, n_jobs=2) #\n",
    "grid.fit(X, y)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.cv_results_)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(datetime.datetime.now()))\n",
    "fh.write('\\n########\\n')\n",
    "fh.write(str(model) + '\\n')  \n",
    "fh.write(str(grid.cv_results_).replace(\", '\", \",\\n'\") + '\\n')\n",
    "fh.write(str(grid.best_score_) + '\\n')  \n",
    "fh.write(str(grid.best_estimator_.alpha) + '\\n')\n",
    "fh.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "papermill": {
     "duration": 0.010044,
     "end_time": "2018-04-01T07:18:30.642900",
     "exception": false,
     "start_time": "2018-04-01T07:18:30.632856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# MODEL: BEST\\nbest = grid.best_estimator_\\n\\nbest.fit(X, y)\\njoblib.dump(best, 'best.pkl') # pickle\\n\\nbest_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\\nbest_performance.compute_measures()\\nprint(best_performance.performance_measures)\\n\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# MODEL: BEST\n",
    "best = grid.best_estimator_\n",
    "\n",
    "best.fit(X, y)\n",
    "joblib.dump(best, 'best.pkl') # pickle\n",
    "\n",
    "best_performance = BinaryClassificationPerformance(best.predict(X), y, 'best')\n",
    "best_performance.compute_measures()\n",
    "print(best_performance.performance_measures)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 8e-06,
     "end_time": "2018-04-01T07:18:30.656700",
     "exception": false,
     "start_time": "2018-04-01T07:18:30.656692",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "papermill": {
     "duration": 0.023661,
     "end_time": "2018-04-01T07:18:30.701634",
     "exception": false,
     "start_time": "2018-04-01T07:18:30.677973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #fits = [svm_performance, lgs_performance, nbs_performance, rdg_performance, prc_performance]\n",
    "# fits = [svm_performance, lgs_performance, rdg_performance, prc_performance]\n",
    "\n",
    "# for fit in fits:\n",
    "#     plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'ro')\n",
    "#     plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "#              fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "# plt.axis([0, 1, 0, 1])\n",
    "# plt.title('ROC plot: training set')\n",
    "# plt.xlabel('False positive rate')\n",
    "# plt.ylabel('True positive rate')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "papermill": {
   "duration": 23659.115805,
   "end_time": "2018-04-01T07:18:31.741292",
   "environment_variables": {},
   "exception": false,
   "output_path": "output.ipynb",
   "parameters": null,
   "start_time": "2018-04-01T00:44:12.625487",
   "version": "0.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}